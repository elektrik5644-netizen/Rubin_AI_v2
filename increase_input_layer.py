#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–£–≤–µ–ª–∏—á–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ Rubin AI
"""

def analyze_input_layer_options():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞—Ä–∏–∞–Ω—Ç—ã —É–≤–µ–ª–∏—á–µ–Ω–∏—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è"""
    
    print("=" * 70)
    print("–ê–ù–ê–õ–ò–ó –£–í–ï–õ–ò–ß–ï–ù–ò–Ø –í–•–û–î–ù–û–ì–û –°–õ–û–Ø RUBIN AI")
    print("=" * 70)
    
    # –¢–µ–∫—É—â–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    current_input = 384
    current_hidden = [512, 256, 128]
    current_output = 10
    
    print(f"–¢–ï–ö–£–©–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:")
    print(f"‚Ä¢ –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π: {current_input} –Ω–µ–π—Ä–æ–Ω–æ–≤")
    print(f"‚Ä¢ –°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏: {current_hidden}")
    print(f"‚Ä¢ –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π: {current_output} –Ω–µ–π—Ä–æ–Ω–æ–≤")
    print(f"‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤: {current_input + sum(current_hidden) + current_output}")
    print()
    
    # –í–∞—Ä–∏–∞–Ω—Ç—ã —É–≤–µ–ª–∏—á–µ–Ω–∏—è
    options = [
        {
            "name": "–í–∞—Ä–∏–∞–Ω—Ç 1: –£–¥–≤–æ–µ–Ω–∏–µ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è",
            "input_size": 768,
            "description": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –±–æ–ª–µ–µ –º–æ—â–Ω–æ–π –º–æ–¥–µ–ª–∏ Sentence Transformer",
            "model": "all-mpnet-base-v2",
            "pros": ["–õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ embeddings", "–ë–æ–ª–µ–µ —Ç–æ—á–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"],
            "cons": ["–ë–æ–ª—å—à–µ –ø–∞–º—è—Ç–∏", "–ú–µ–¥–ª–µ–Ω–Ω–µ–µ –æ–±—Ä–∞–±–æ—Ç–∫–∞"]
        },
        {
            "name": "–í–∞—Ä–∏–∞–Ω—Ç 2: –¢—Ä–æ–π–Ω–æ–µ —É–≤–µ–ª–∏—á–µ–Ω–∏–µ",
            "input_size": 1152,
            "description": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Å–∞–º–æ–π –º–æ—â–Ω–æ–π –º–æ–¥–µ–ª–∏ Sentence Transformer",
            "model": "all-MiniLM-L12-v2",
            "pros": ["–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ", "–õ—É—á—à–∞—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"],
            "cons": ["–ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤", "–ú–µ–¥–ª–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞"]
        },
        {
            "name": "–í–∞—Ä–∏–∞–Ω—Ç 3: –ö–∞—Å—Ç–æ–º–Ω—ã–π —Ä–∞–∑–º–µ—Ä",
            "input_size": 512,
            "description": "–ö–æ–º–ø—Ä–æ–º–∏—Å—Å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏",
            "model": "all-MiniLM-L6-v2 + –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏",
            "pros": ["–ë–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏", "–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –º–µ—Ç–∞-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤"],
            "cons": ["–¢—Ä–µ–±—É–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–¥–∞"]
        },
        {
            "name": "–í–∞—Ä–∏–∞–Ω—Ç 4: –ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤—ã–µ embeddings",
            "input_size": 1024,
            "description": "–ö–æ–º–±–∏–Ω–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π embeddings",
            "model": "all-MiniLM-L6-v2 + all-mpnet-base-v2",
            "pros": ["–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å", "–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π"],
            "cons": ["–°–ª–æ–∂–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞", "–í—ã—Å–æ–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ä–µ—Å—É—Ä—Å–∞–º"]
        }
    ]
    
    for i, option in enumerate(options, 1):
        print(f"{option['name']}:")
        print(f"  ‚Ä¢ –†–∞–∑–º–µ—Ä –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è: {option['input_size']} –Ω–µ–π—Ä–æ–Ω–æ–≤")
        print(f"  ‚Ä¢ –ú–æ–¥–µ–ª—å: {option['model']}")
        print(f"  ‚Ä¢ –û–ø–∏—Å–∞–Ω–∏–µ: {option['description']}")
        
        # –†–∞—Å—á–µ—Ç –Ω–æ–≤–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
        new_hidden = [option['input_size'] * 2, option['input_size'], option['input_size'] // 2]
        total_neurons = option['input_size'] + sum(new_hidden) + current_output
        total_weights = (option['input_size'] * new_hidden[0] + 
                        new_hidden[0] * new_hidden[1] + 
                        new_hidden[1] * new_hidden[2] + 
                        new_hidden[2] * current_output)
        
        print(f"  ‚Ä¢ –ù–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {option['input_size']} -> {new_hidden} -> {current_output}")
        print(f"  ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤: {total_neurons}")
        print(f"  ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Å–æ–≤: {total_weights:,}")
        print(f"  ‚Ä¢ –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–æ–≤: {((total_neurons - (current_input + sum(current_hidden) + current_output)) / (current_input + sum(current_hidden) + current_output) * 100):.1f}%")
        
        print(f"  ‚Ä¢ –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: {', '.join(option['pros'])}")
        print(f"  ‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–∫–∏: {', '.join(option['cons'])}")
        print()
    
    return options

def create_enhanced_neural_network(input_size=768):
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –≤—Ö–æ–¥–Ω—ã–º —Å–ª–æ–µ–º"""
    
    print("=" * 70)
    print(f"–°–û–ó–î–ê–ù–ò–ï –£–õ–£–ß–®–ï–ù–ù–û–ô –ù–ï–ô–†–û–ù–ù–û–ô –°–ï–¢–ò (–≤—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π: {input_size})")
    print("=" * 70)
    
    # –ù–æ–≤–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
    hidden_sizes = [input_size * 2, input_size, input_size // 2]
    num_classes = 10
    
    print(f"–ù–û–í–ê–Ø –ê–†–•–ò–¢–ï–ö–¢–£–†–ê:")
    print(f"‚Ä¢ –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π: {input_size} –Ω–µ–π—Ä–æ–Ω–æ–≤")
    print(f"‚Ä¢ –°–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏: {hidden_sizes}")
    print(f"‚Ä¢ –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π: {num_classes} –Ω–µ–π—Ä–æ–Ω–æ–≤")
    
    total_neurons = input_size + sum(hidden_sizes) + num_classes
    print(f"‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–µ–π—Ä–æ–Ω–æ–≤: {total_neurons}")
    
    # –†–∞—Å—á–µ—Ç –≤–µ—Å–æ–≤
    weights = (input_size * hidden_sizes[0] + 
              hidden_sizes[0] * hidden_sizes[1] + 
              hidden_sizes[1] * hidden_sizes[2] + 
              hidden_sizes[2] * num_classes)
    print(f"‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–µ—Å–æ–≤: {weights:,}")
    
    return {
        'input_size': input_size,
        'hidden_sizes': hidden_sizes,
        'num_classes': num_classes,
        'total_neurons': total_neurons,
        'total_weights': weights
    }

def generate_implementation_code(input_size=768):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–æ–¥ –¥–ª—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —É–≤–µ–ª–∏—á–µ–Ω–Ω–æ–≥–æ –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è"""
    
    print("=" * 70)
    print("–ö–û–î –î–õ–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–ò –£–í–ï–õ–ò–ß–ï–ù–ù–û–ì–û –í–•–û–î–ù–û–ì–û –°–õ–û–Ø")
    print("=" * 70)
    
    code = f'''
# –û–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
def initialize_enhanced_models(self):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –≤—Ö–æ–¥–Ω—ã–º —Å–ª–æ–µ–º"""
    try:
        logger.info("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏...")
        
        if SENTENCE_TRANSFORMERS_AVAILABLE:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è embeddings
            self.sentence_model = SentenceTransformer('all-mpnet-base-v2')  # 768 —Ä–∞–∑–º–µ—Ä
            logger.info("‚úÖ –£–ª—É—á—à–µ–Ω–Ω—ã–π Sentence Transformer –∑–∞–≥—Ä—É–∂–µ–Ω (768 —Ä–∞–∑–º–µ—Ä)")
        else:
            logger.warning("‚ö†Ô∏è SentenceTransformer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º mock")
            self.sentence_model = None
        
        if ML_AVAILABLE:
            # –£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –≤—Ö–æ–¥–Ω—ã–º —Å–ª–æ–µ–º
            self.neural_network = RubinNeuralNetwork(
                input_size={input_size},  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä embeddings
                hidden_sizes=[{input_size * 2}, {input_size}, {input_size // 2}],  # –ü—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏
                num_classes=len(self.categories),
                activations=['ReLU', 'ReLU', 'ReLU'],  # –ú–æ–∂–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å
                dropout_rates=[0.2, 0.2]  # Dropout –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è
            ).to(self.device)
            
            logger.info("‚úÖ –£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
            
        else:
            logger.warning("‚ö†Ô∏è PyTorch –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º mock –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å")
            self.neural_network = None
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏: {{e}}")
        # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
        self.sentence_model = None
        self.neural_network = None

# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ —Å–æ–∑–¥–∞–Ω–∏—è embeddings
def create_enhanced_embedding(self, text):
    """–°–æ–∑–¥–∞–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
    try:
        if self.sentence_model and SENTENCE_TRANSFORMERS_AVAILABLE:
            embedding = self.sentence_model.encode(text)
            if ML_AVAILABLE:
                return torch.FloatTensor(embedding).unsqueeze(0).to(self.device)
            else:
                return embedding
        else:
            # –ü—Ä–æ—Å—Ç–æ–π fallback —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            import random
            random.seed(len(text))  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥
            return [random.random() for _ in range({input_size})]
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {{e}}")
        return [0.1] * {input_size}
'''
    
    print(code)
    return code

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    # –ê–Ω–∞–ª–∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    options = analyze_input_layer_options()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —É–ª—É—á—à–µ–Ω–Ω–æ–π —Å–µ—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–∞—Ä–∏–∞–Ω—Ç–∞
    for option in options:
        print("=" * 70)
        print(f"–ê–ù–ê–õ–ò–ó –í–ê–†–ò–ê–ù–¢–ê: {option['name']}")
        print("=" * 70)
        
        enhanced_network = create_enhanced_neural_network(option['input_size'])
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞
        implementation_code = generate_implementation_code(option['input_size'])
        
        print()
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print("=" * 70)
    print("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–í–ï–õ–ò–ß–ï–ù–ò–Æ –í–•–û–î–ù–û–ì–û –°–õ–û–Ø")
    print("=" * 70)
    
    recommendations = [
        "1. –ù–∞—á–Ω–∏—Ç–µ —Å –í–∞—Ä–∏–∞–Ω—Ç–∞ 1 (768 –Ω–µ–π—Ä–æ–Ω–æ–≤) - –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
        "2. –û–±–Ω–æ–≤–∏—Ç–µ Sentence Transformer –Ω–∞ 'all-mpnet-base-v2' –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è 768-–º–µ—Ä–Ω—ã—Ö embeddings",
        "3. –£–≤–µ–ª–∏—á—å—Ç–µ —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –≤—Ö–æ–¥–Ω–æ–º—É —Å–ª–æ—é",
        "4. –î–æ–±–∞–≤—å—Ç–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è",
        "5. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é (dropout, weight decay) –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è",
        "6. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
        "7. –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è"
    ]
    
    for rec in recommendations:
        print(f"‚Ä¢ {rec}")
    
    print()
    print("=" * 70)
    print("–®–ê–ì–ò –î–õ–Ø –†–ï–ê–õ–ò–ó–ê–¶–ò–ò")
    print("=" * 70)
    
    steps = [
        "1. –û–±–Ω–æ–≤–∏—Ç–µ Sentence Transformer –Ω–∞ –±–æ–ª–µ–µ –º–æ—â–Ω—É—é –º–æ–¥–µ–ª—å",
        "2. –ò–∑–º–µ–Ω–∏—Ç–µ input_size –≤ RubinNeuralNetwork —Å 384 –Ω–∞ 768",
        "3. –û–±–Ω–æ–≤–∏—Ç–µ —Å–∫—Ä—ã—Ç—ã–µ —Å–ª–æ–∏ –¥–ª—è —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–æ–≤–æ–º—É –≤—Ö–æ–¥–Ω–æ–º—É —Ä–∞–∑–º–µ—Ä—É",
        "4. –ü–µ—Ä–µ–æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
        "5. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏",
        "6. –û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"
    ]
    
    for step in steps:
        print(f"‚Ä¢ {step}")

if __name__ == "__main__":
    main()





