#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
API –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è
"""

import sqlite3
import json
import re
from typing import List, Dict, Tuple, Set
from datetime import datetime
from http.server import BaseHTTPRequestHandler, HTTPServer
import urllib.parse

class VocabularyEnhancedAPI:
    """API –∫–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ª–æ–≤–∞—Ä—è"""
    
    def __init__(self, db_path: str = "rubin_ai_v2.db"):
        self.db_path = db_path
        self.connection = None
        self.connect_database()
    
    def connect_database(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.connection = sqlite3.connect(self.db_path)
            self.connection.execute("PRAGMA foreign_keys = ON")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            raise
    
    def get_synonyms(self, term: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –¥–ª—è —Ç–µ—Ä–º–∏–Ω–∞"""
        try:
            cursor = self.connection.cursor()
            
            cursor.execute("""
                SELECT DISTINCT synonym FROM technical_synonyms 
                WHERE main_term = ? OR synonym = ?
                UNION
                SELECT DISTINCT synonym FROM synonyms 
                WHERE term = ? OR synonym = ?
            """, (term, term, term, term))
            
            synonyms = [row[0] for row in cursor.fetchall()]
            return synonyms
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤: {e}")
            return []
    
    def expand_query_with_synonyms(self, query: str) -> Dict[str, List[str]]:
        """–†–∞—Å—à–∏—Ä–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏"""
        try:
            words = re.findall(r'\b\w+\b', query.lower())
            expanded_terms = {}
            
            for word in words:
                if len(word) > 2:
                    synonyms = self.get_synonyms(word)
                    if synonyms:
                        expanded_terms[word] = synonyms
            
            return expanded_terms
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return {}
    
    def search_documents_with_synonyms(self, query: str, limit: int = 10, category: str = None) -> List[Dict]:
        """–ü–æ–∏—Å–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–∏–Ω–æ–Ω–∏–º–æ–≤"""
        try:
            cursor = self.connection.cursor()
            
            expanded_terms = self.expand_query_with_synonyms(query)
            search_terms = [query]
            
            for term, synonyms in expanded_terms.items():
                search_terms.extend(synonyms)
            
            search_terms = list(set(search_terms))
            
            # –ë–∞–∑–æ–≤—ã–π SQL –∑–∞–ø—Ä–æ—Å
            base_sql = """
                SELECT DISTINCT 
                    id, file_name, content, category, tags, difficulty_level,
                    CASE 
                        WHEN content LIKE ? THEN 3
                        WHEN content LIKE ? THEN 2
                        ELSE 1
                    END as relevance_score
                FROM documents 
                WHERE {placeholders}
            """
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if category:
                base_sql += " AND category = ?"
            
            base_sql += """
                ORDER BY relevance_score DESC, id DESC
                LIMIT ?
            """
            
            placeholders = ' OR '.join(['content LIKE ?' for _ in search_terms])
            sql_query = base_sql.format(placeholders=placeholders)
            
            params = []
            for term in search_terms:
                params.append(f'%{term}%')
            
            params.append(f'%{query}%')
            params.append(f'%{query}%')
            
            if category:
                params.append(category)
            
            params.append(limit)
            
            cursor.execute(sql_query, params)
            results = cursor.fetchall()
            
            formatted_results = []
            for row in results:
                formatted_results.append({
                    'id': row[0],
                    'file_name': row[1],
                    'content': row[2][:500] + '...' if len(row[2]) > 500 else row[2],
                    'category': row[3],
                    'tags': row[4],
                    'difficulty_level': row[5],
                    'relevance_score': row[6],
                    'matched_terms': self.find_matched_terms(row[2], search_terms),
                    'synonyms_used': list(expanded_terms.keys())
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
            return []
    
    def find_matched_terms(self, content: str, search_terms: List[str]) -> List[str]:
        """–ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–≤—à–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ"""
        matched = []
        content_lower = content.lower()
        
        for term in search_terms:
            if term.lower() in content_lower:
                matched.append(term)
        
        return matched
    
    def get_category_suggestions(self, query: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º"""
        try:
            cursor = self.connection.cursor()
            
            cursor.execute("""
                SELECT DISTINCT category, COUNT(*) as count
                FROM technical_synonyms 
                WHERE main_term LIKE ? OR synonym LIKE ?
                GROUP BY category
                ORDER BY count DESC
                LIMIT 5
            """, (f'%{query}%', f'%{query}%'))
            
            categories = [row[0] for row in cursor.fetchall()]
            return categories
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π: {e}")
            return []
    
    def get_related_terms(self, term: str) -> List[str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        try:
            cursor = self.connection.cursor()
            
            cursor.execute("""
                SELECT DISTINCT main_term
                FROM technical_synonyms 
                WHERE category = (
                    SELECT category FROM technical_synonyms 
                    WHERE main_term = ? OR synonym = ? 
                    LIMIT 1
                )
                AND main_term != ?
                LIMIT 10
            """, (term, term, term))
            
            related = [row[0] for row in cursor.fetchall()]
            return related
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤: {e}")
            return []
    
    def get_vocabulary_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —Å–ª–æ–≤–∞—Ä—è"""
        try:
            cursor = self.connection.cursor()
            
            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cursor.execute("SELECT COUNT(*) FROM technical_synonyms")
            total_synonyms = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(DISTINCT main_term) FROM technical_synonyms")
            unique_terms = cursor.fetchone()[0]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
            cursor.execute("""
                SELECT category, COUNT(*) as count
                FROM technical_synonyms
                GROUP BY category
                ORDER BY count DESC
            """)
            categories = cursor.fetchall()
            
            return {
                'total_synonyms': total_synonyms,
                'unique_terms': unique_terms,
                'categories': [{'name': cat[0], 'count': cat[1]} for cat in categories],
                'last_updated': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}
    
    def close_connection(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        if self.connection:
            self.connection.close()

class VocabularyAPIHandler(BaseHTTPRequestHandler):
    """HTTP –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è API"""
    
    def __init__(self, *args, **kwargs):
        self.vocabulary_api = VocabularyEnhancedAPI()
        super().__init__(*args, **kwargs)
    
    def do_GET(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ GET –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            parsed_path = urllib.parse.urlparse(self.path)
            path = parsed_path.path
            query_params = urllib.parse.parse_qs(parsed_path.query)
            
            if path == '/api/vocabulary/search':
                self.handle_search(query_params)
            elif path == '/api/vocabulary/synonyms':
                self.handle_synonyms(query_params)
            elif path == '/api/vocabulary/categories':
                self.handle_categories(query_params)
            elif path == '/api/vocabulary/related':
                self.handle_related(query_params)
            elif path == '/api/vocabulary/stats':
                self.handle_stats()
            else:
                self.send_error(404, "Endpoint not found")
                
        except Exception as e:
            self.send_error(500, f"Internal server error: {str(e)}")
    
    def do_POST(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ POST –∑–∞–ø—Ä–æ—Å–æ–≤"""
        try:
            content_length = int(self.headers['Content-Length'])
            post_data = self.rfile.read(content_length)
            data = json.loads(post_data.decode('utf-8'))
            
            parsed_path = urllib.parse.urlparse(self.path)
            path = parsed_path.path
            
            if path == '/api/vocabulary/search':
                self.handle_search_post(data)
            else:
                self.send_error(404, "Endpoint not found")
                
        except Exception as e:
            self.send_error(500, f"Internal server error: {str(e)}")
    
    def handle_search(self, params):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (GET)"""
        query = params.get('q', [''])[0]
        limit = int(params.get('limit', ['10'])[0])
        category = params.get('category', [None])[0]
        
        if not query:
            self.send_error(400, "Query parameter 'q' is required")
            return
        
        results = self.vocabulary_api.search_documents_with_synonyms(query, limit, category)
        suggestions = self.vocabulary_api.get_category_suggestions(query)
        
        response = {
            'query': query,
            'results': results,
            'suggestions': suggestions,
            'total_found': len(results),
            'timestamp': datetime.now().isoformat()
        }
        
        self.send_json_response(response)
    
    def handle_search_post(self, data):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–∏—Å–∫–æ–≤–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (POST)"""
        query = data.get('query', '')
        limit = data.get('limit', 10)
        category = data.get('category')
        
        if not query:
            self.send_error(400, "Field 'query' is required")
            return
        
        results = self.vocabulary_api.search_documents_with_synonyms(query, limit, category)
        suggestions = self.vocabulary_api.get_category_suggestions(query)
        expanded_terms = self.vocabulary_api.expand_query_with_synonyms(query)
        
        response = {
            'query': query,
            'results': results,
            'suggestions': suggestions,
            'expanded_terms': expanded_terms,
            'total_found': len(results),
            'timestamp': datetime.now().isoformat()
        }
        
        self.send_json_response(response)
    
    def handle_synonyms(self, params):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤"""
        term = params.get('term', [''])[0]
        
        if not term:
            self.send_error(400, "Parameter 'term' is required")
            return
        
        synonyms = self.vocabulary_api.get_synonyms(term)
        
        response = {
            'term': term,
            'synonyms': synonyms,
            'count': len(synonyms),
            'timestamp': datetime.now().isoformat()
        }
        
        self.send_json_response(response)
    
    def handle_categories(self, params):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π"""
        query = params.get('q', [''])[0]
        
        if query:
            categories = self.vocabulary_api.get_category_suggestions(query)
        else:
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤—Å–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            stats = self.vocabulary_api.get_vocabulary_stats()
            categories = [cat['name'] for cat in stats.get('categories', [])]
        
        response = {
            'categories': categories,
            'count': len(categories),
            'timestamp': datetime.now().isoformat()
        }
        
        self.send_json_response(response)
    
    def handle_related(self, params):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤"""
        term = params.get('term', [''])[0]
        
        if not term:
            self.send_error(400, "Parameter 'term' is required")
            return
        
        related = self.vocabulary_api.get_related_terms(term)
        
        response = {
            'term': term,
            'related_terms': related,
            'count': len(related),
            'timestamp': datetime.now().isoformat()
        }
        
        self.send_json_response(response)
    
    def handle_stats(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        stats = self.vocabulary_api.get_vocabulary_stats()
        self.send_json_response(stats)
    
    def send_json_response(self, data):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ JSON –æ—Ç–≤–µ—Ç–∞"""
        self.send_response(200)
        self.send_header('Content-type', 'application/json; charset=utf-8')
        self.send_header('Access-Control-Allow-Origin', '*')
        self.end_headers()
        
        json_data = json.dumps(data, ensure_ascii=False, indent=2)
        self.wfile.write(json_data.encode('utf-8'))
    
    def log_message(self, format, *args):
        """–û—Ç–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        pass

def run_server(port=8085):
    """–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞"""
    server_address = ('', port)
    httpd = HTTPServer(server_address, VocabularyAPIHandler)
    
    print(f"üöÄ Vocabulary Enhanced API Server –∑–∞–ø—É—â–µ–Ω –Ω–∞ –ø–æ—Ä—Ç—É {port}")
    print(f"üì° –î–æ—Å—Ç—É–ø–Ω—ã–µ endpoints:")
    print(f"  GET  /api/vocabulary/search?q=query&limit=10&category=category")
    print(f"  POST /api/vocabulary/search")
    print(f"  GET  /api/vocabulary/synonyms?term=term")
    print(f"  GET  /api/vocabulary/categories?q=query")
    print(f"  GET  /api/vocabulary/related?term=term")
    print(f"  GET  /api/vocabulary/stats")
    print(f"üåê –û—Ç–∫—Ä–æ–π—Ç–µ: http://localhost:{port}/api/vocabulary/stats")
    
    try:
        httpd.serve_forever()
    except KeyboardInterrupt:
        print("\nüõë –°–µ—Ä–≤–µ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        httpd.server_close()

if __name__ == "__main__":
    run_server()






















