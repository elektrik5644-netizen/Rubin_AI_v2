#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Neural Rubin AI - –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–ª—è Rubin AI
–ù–∞—Å—Ç–æ—è—â–∏–π AI —Å –æ–±—É—á–µ–Ω–∏–µ–º –∏ —Ä–∞–∑–≤–∏—Ç–∏–µ–º
"""

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ ML –±–∏–±–ª–∏–æ—Ç–µ–∫ —Å fallback
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    # Mock –∫–ª–∞—Å—Å—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ ML –±–∏–±–ª–∏–æ—Ç–µ–∫
    class torch:
        @staticmethod
        def device(name):
            return name
        
        @staticmethod
        def cuda_is_available():
            return False
        
        @staticmethod
        def FloatTensor(data):
            return data
        
        @staticmethod
        def randn(*args):
            return [0.1] * (args[0] * args[1] if len(args) > 1 else args[0])
        
        @staticmethod
        def argmax(tensor, dim=None):
            return 0  # Mock category index
        
        @staticmethod
        def max(tensor):
            return 0.85  # Mock confidence
        
        @staticmethod
        def no_grad():
            class NoGradContext:
                def __enter__(self): return self
                def __exit__(self, *args): pass
            return NoGradContext()
    
    class nn:
        class Module:
            def __init__(self): pass
            def to(self, device): return self
            def state_dict(self): return {}
            def load_state_dict(self, state_dict): pass

try:
    from transformers import AutoTokenizer, AutoModel
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
import json
import numpy as np
from datetime import datetime
import logging
import pickle
import os
from mathematical_problem_solver import MathematicalProblemSolver, ProblemSolution, ProblemType
from rubin_time_series_processor import RubinTimeSeriesProcessor, NPriceType
import re # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
import csv # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è
from typing import Optional, Tuple, List, Dict, Any # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è Optional —Ç–∏–ø–∏–∑–∞—Ü–∏–∏
import matplotlib.pyplot as plt # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
from rubin_data_preprocessor import RubinDataPreprocessor # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
ACTIVATION_FUNCTIONS = {
    'ReLU': nn.ReLU,
    'Tanh': nn.Tanh,
    'Softsign': nn.Softsign,
    'Sigmoid': nn.Sigmoid, # –ß–∞—Å—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    'ELU': nn.ELU,
    'LeakyReLU': nn.LeakyReLU, # –†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç ReLU
    # 'Arctg':, 'PReLU':, 'SoftPlus':, 'Sin':, 'Sinc':, 'Gaussian': - —ç—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç—Ä–µ–±—É—é—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏, —Ç–∞–∫ –∫–∞–∫ –∏—Ö –Ω–µ—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ nn
}

class RubinNeuralNetwork(nn.Module):
    """–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å Rubin AI"""
    
    def __init__(self, input_size=384, hidden_sizes=[512, 256, 128], num_classes=10, activations=None, dropout_rates=None):
        super(RubinNeuralNetwork, self).__init__()
        
        if activations is None:
            activations = ['ReLU'] * len(hidden_sizes) # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é ReLU –¥–ª—è –≤—Å–µ—Ö —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤

        if dropout_rates is None:
            dropout_rates = [0.2] * (len(hidden_sizes) - 1) # Dropout –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–≥–æ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è, –∫—Ä–æ–º–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –¥–ª–∏–Ω
        if len(activations) != len(hidden_sizes):
            raise ValueError("–î–ª–∏–Ω–∞ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–∞—Ü–∏–π –¥–æ–ª–∂–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤.")
        if len(dropout_rates) != (len(hidden_sizes) - 1):
            logger.warning("‚ö†Ô∏è –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ dropout-—Å–ª–æ–µ–≤ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ–µ–≤ - 1. –ë—É–¥—É—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω—ã –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            dropout_rates = [0.2] * (len(hidden_sizes) - 1)

        layers = []
        current_size = input_size
        
        for i, hidden_size in enumerate(hidden_sizes):
            layers.append(nn.Linear(current_size, hidden_size))
            
            activation_name = activations[i]
            if activation_name not in ACTIVATION_FUNCTIONS:
                raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: {activation_name}. –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(ACTIVATION_FUNCTIONS.keys())}")
            layers.append(ACTIVATION_FUNCTIONS[activation_name]())

            if i < len(hidden_sizes) - 1 and dropout_rates[i] > 0:
                layers.append(nn.Dropout(dropout_rates[i]))
            
            current_size = hidden_size
            
        layers.append(nn.Linear(current_size, num_classes))
        
        self.encoder = nn.Sequential(*layers)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Ç–∏–ø–æ–≤ –≤–æ–ø—Ä–æ—Å–æ–≤
        self.classifier = nn.Softmax(dim=1)
        
    def forward(self, x):
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ —Å–µ—Ç—å"""
        encoded = self.encoder(x)
        classified = self.classifier(encoded)
        return classified

class NeuralRubinAI:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ Rubin AI"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.sentence_model = None
        self.neural_network = None
        self.tokenizer = None
        self.knowledge_base = {}
        self.conversation_history = []
        self.math_solver = MathematicalProblemSolver() # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–∞—Ç–µ–ª—è
        self.time_series_processor = RubinTimeSeriesProcessor() # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        self.data_preprocessor = RubinDataPreprocessor() # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤
        self.categories = [
            '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞', '—Ñ–∏–∑–∏–∫–∞', '—ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ',
            '–≥–µ–æ–º–µ—Ç—Ä–∏—è', '—Ö–∏–º–∏—è', '–æ–±—â–∏–µ_–≤–æ–ø—Ä–æ—Å—ã', '—Ç–µ—Ö–Ω–∏–∫–∞', '–Ω–∞—É–∫–∞', '–¥—Ä—É–≥–æ–µ',
            'time_series', 'graph_analysis', 'data_visualization', 'formula_calculation'
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é physics, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
        if 'physics' not in self.categories:
            self.categories.insert(1, 'physics') # –í—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏
        
        # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏
        self.enhanced_dispatcher = None
        self.programming_handler = None
        self.electrical_handler = None
        self.enhanced_categorizer = None
        
        self.initialize_models()
        self.initialize_enhanced_handlers()
    
    def initialize_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
        try:
            logger.info("üß† –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏...")
            
            if SENTENCE_TRANSFORMERS_AVAILABLE:
                # –ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
                self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')
                logger.info("‚úÖ Sentence Transformer –∑–∞–≥—Ä—É–∂–µ–Ω")
            else:
                logger.warning("‚ö†Ô∏è SentenceTransformer –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º mock")
                self.sentence_model = None
            
            if ML_AVAILABLE:
                # –ù–∞—à–∞ –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å
                self.neural_network = RubinNeuralNetwork(
                    input_size=384,  # –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
                    hidden_sizes=[1024, 512, 256, 128], # –°–µ—Ç—å —Å–¥–µ–ª–∞–Ω–∞ –≥–ª—É–±–∂–µ –∏ —à–∏—Ä–µ
                    num_classes=len(self.categories)
                ).to(self.device)
                
                logger.info("‚úÖ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
                
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –µ—Å—Ç—å (–∑–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å –≥–∏–±–∫–∏–º–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è–º–∏)
                # self.load_model()
            else:
                logger.warning("‚ö†Ô∏è PyTorch –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º mock –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å")
                self.neural_network = None
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏
            self.sentence_model = None
            self.neural_network = None
    
    def initialize_enhanced_handlers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"""
        try:
            logger.info("üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏...")
            
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            from intelligent_dispatcher import get_intelligent_dispatcher
            from programming_knowledge_handler import get_programming_handler
            from electrical_knowledge_handler import get_electrical_handler
            from enhanced_request_categorizer import get_enhanced_categorizer
            
            self.enhanced_dispatcher = get_intelligent_dispatcher()
            self.programming_handler = get_programming_handler()
            self.electrical_handler = get_electrical_handler()
            self.enhanced_categorizer = get_enhanced_categorizer()
            
            logger.info("‚úÖ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º–∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞–º–∏!")
            logger.info(f"–î–∏—Å–ø–µ—Ç—á–µ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –º–æ–¥—É–ª–µ–π: {self.enhanced_dispatcher.module_metrics}") # –î–æ–±–∞–≤–ª—è–µ–º –ª–æ–≥
            
        except ImportError as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å —É–ª—É—á—à–µ–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏: {e}")
            self.enhanced_dispatcher = None
            self.programming_handler = None
            self.electrical_handler = None
            self.enhanced_categorizer = None
    
    def create_embedding(self, text):
        """–°–æ–∑–¥–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            if self.sentence_model and SENTENCE_TRANSFORMERS_AVAILABLE:
                embedding = self.sentence_model.encode(text)
                if ML_AVAILABLE:
                    return torch.FloatTensor(embedding).unsqueeze(0).to(self.device)
                else:
                    return embedding
            else:
                # –ü—Ä–æ—Å—Ç–æ–π fallback —ç–º–±–µ–¥–¥–∏–Ω–≥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                import random
                random.seed(len(text))  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥
                return [random.random() for _ in range(384)]
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            return [0.1] * 384
    
    def classify_question(self, text):
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        try:
            if not self.neural_network or not ML_AVAILABLE:
                return self._simple_classification(text)
            
            # –°–æ–∑–¥–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
            embedding = self.create_embedding(text)
            
            # –ü—Ä–æ–≥–æ–Ω—è–µ–º —á–µ—Ä–µ–∑ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
            with torch.no_grad():
                output = self.neural_network(embedding)
                predicted_class = torch.argmax(output, dim=1).item()
            
            category = self.categories[predicted_class]
            confidence = float(torch.max(output).item())
            
            logger.info(f"üéØ –ù–µ–π—Ä–æ–Ω–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {category} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
            return category, confidence
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏: {e}")
            return self._simple_classification(text)
    
    def _simple_classification(self, text):
        """–ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –±–µ–∑ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        text_lower = text.lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        keywords = {
            '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞': ['—Å–∫–æ–ª—å–∫–æ', '+', '-', '*', '/', '–≤—ã—á–∏—Å–ª–∏', '—Ä–µ—à–∏'],
            '—Ñ–∏–∑–∏–∫–∞': ['—Å–∫–æ—Ä–æ—Å—Ç—å', '–≤—Ä–µ–º—è', '—Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ', '—Å–∏–ª–∞', '—ç–Ω–µ—Ä–≥–∏—è'],
            '—ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞': ['—Ç—Ä–∞–Ω–∑–∏—Å—Ç–æ—Ä', '–¥–∏–æ–¥', '—Ç–æ–∫', '–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ', '—Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ'],
            '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ': ['–∫–æ–¥', 'python', 'c++', '–∞–ª–≥–æ—Ä–∏—Ç–º', '–ø—Ä–æ–≥—Ä–∞–º–º–∞'],
            '–≥–µ–æ–º–µ—Ç—Ä–∏—è': ['—É–≥–æ–ª', '—Ç—Ä–µ—É–≥–æ–ª—å–Ω–∏–∫', '–ø–ª–æ—â–∞–¥—å', '–ø–µ—Ä–∏–º–µ—Ç—Ä']
        }
        
        for category, words in keywords.items():
            if any(word in text_lower for word in words):
                return category, 0.8
        
        return '–æ–±—â–∏–µ_–≤–æ–ø—Ä–æ—Å—ã', 0.5
    
    def generate_response(self, question):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"""
        try:
            logger.info(f"üß† –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç: {question[:50]}...")
            
            # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —É–ª—É—á—à–µ–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            if self.enhanced_categorizer and self.enhanced_dispatcher:
                logger.info("üîó –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—é –≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ç–æ—Ä
                category = self.enhanced_categorizer.categorize(question)
                confidence = self.enhanced_categorizer.get_confidence(question, category)
                
                logger.info(f"üéØ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å + —É–ª—É—á—à–µ–Ω–Ω–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è: {category} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.2f})")
                
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏
                request_data = {'message': question}
                
                if category == 'programming' and self.programming_handler:
                    response_data = self.programming_handler.handle_request(question)
                    response = response_data['response']
                    provider = f"Neural + {response_data.get('provider', 'Programming Handler')}"
                    
                elif category == 'electrical' and self.electrical_handler:
                    response_data = self.electrical_handler.handle_request(question)
                    response = response_data['response']
                    provider = f"Neural + {response_data.get('provider', 'Electrical Handler')}"
                    
                elif category.startswith('mathematics'):
                    response_data = self.enhanced_dispatcher._handle_mathematical_request(request_data)
                    response = response_data['response']
                    provider = f"Neural + {response_data.get('provider', 'Mathematical Handler')}"
                    
                elif category == 'time_series' and self.time_series_processor:
                    # –ó–∞–º–µ–Ω—è–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–∑–æ–≤ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥
                    response = self._solve_time_series_neural(question)
                    provider = "Neural + Time Series Handler"
                    
                elif category == 'physics' or category == 'formula_calculation':
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª
                    response = self._solve_physics_neural(question)
                    provider = "Neural + Physics Handler"
                    
                elif category == 'chemistry':
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª
                    response = self._solve_chemistry_neural(question)
                    provider = "Neural + Chemistry Handler"
                    
                elif category == 'graph_analysis':
                    # –ê–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∏–∫–æ–≤
                    response = self._analyze_graph_neural(question)
                    provider = "Neural + Graph Analysis Handler"
                    
                elif category == 'data_visualization':
                    # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
                    response = self._create_visualization_neural(question)
                    provider = "Neural + Data Visualization Handler"
                    
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–±—â–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
                    response_data = self.enhanced_dispatcher._handle_general_request(request_data)
                    response = response_data['response']
                    provider = f"Neural + {response_data.get('provider', 'General Handler')}"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É –∫ –æ—Ç–≤–µ—Ç—É
                neural_enhanced_response = f"""üß† **–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å Rubin AI + –£–ª—É—á—à–µ–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏**

{response}

---
*–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏–µ–π: {category} (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%})*"""
                
            else:
                # Fallback –∫ —Å—Ç–∞—Ä–æ–π –ª–æ–≥–∏–∫–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
                logger.info("‚ö†Ô∏è –£–ª—É—á—à–µ–Ω–Ω—ã–µ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—É—é –Ω–µ–π—Ä–æ–Ω–Ω—É—é –ª–æ–≥–∏–∫—É")
                category, confidence = self.classify_question(question)
                neural_enhanced_response = self._generate_category_response(question, category, confidence)
                provider = "Neural Rubin AI (Fallback)"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
                neural_info = f"\n\nüß† **–ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å:** –ö–∞—Ç–µ–≥–æ—Ä–∏—è '{category}' (—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {confidence:.1%})"
                neural_enhanced_response += neural_info
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
            self.conversation_history.append({
                'timestamp': datetime.now().isoformat(),
                'question': question,
                'category': category,
                'confidence': confidence,
                'enhanced_processing': self.enhanced_categorizer is not None
            })
            
            return {
                'response': neural_enhanced_response,
                'category': category,
                'confidence': confidence,
                'neural_network': True,
                'enhanced_integration': self.enhanced_categorizer is not None,
                'provider': provider,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {
                'response': f'–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏: {str(e)}',
                'category': 'error',
                'confidence': 0.0,
                'neural_network': False,
                'provider': 'Neural Error Handler'
            }
    
    def _generate_category_response(self, question, category, confidence):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        
        if category == '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞':
            return self._solve_math_neural(question)
        elif category == '—Ñ–∏–∑–∏–∫–∞':
            return self._solve_physics_neural(question)
        elif category == '—ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞':
            return self._explain_electronics_neural(question)
        elif category == '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ':
            return self._explain_programming_neural(question)
        elif category == 'time_series':
            return self._solve_time_series_neural(question)
        else:
            return self._general_response_neural(question, category)
    
    def _solve_math_neural(self, question):
        """
        –†–µ—à–∞–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏.
        –ó–¥–µ—Å—å –±—É–¥–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–∞—è –ª–æ–≥–∏–∫–∞ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–∞—Å—á–µ—Ç–æ–≤.
        """
        try:
            solution = self.math_solver.solve_problem(question)
            
            if solution.problem_type != ProblemType.UNKNOWN and solution.final_answer is not None:
                answer_str = str(solution.final_answer)
                if isinstance(solution.final_answer, dict):
                    answer_str = ', '.join([f'{k}={v:.2f}' for k, v in solution.final_answer.items()])
                elif isinstance(solution.final_answer, (float, int)):
                    answer_str = f'{solution.final_answer:.2f}'

                steps_str = "\n".join([f'    - {step}' for step in solution.solution_steps])
                
                return f"""üßÆ **–ù–µ–π—Ä–æ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏:**\n\n**–ó–∞–¥–∞—á–∞:** {question}\n**–¢–∏–ø –∑–∞–¥–∞—á–∏:** {solution.problem_type.value}\n**–û—Ç–≤–µ—Ç:** {answer_str}\n\n**–ü–æ—à–∞–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ:**\n{steps_str}\n\n**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {solution.explanation}\n\n**–ü—Ä–æ—Ü–µ—Å—Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏:**\n1. –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª–∞ –≤–æ–ø—Ä–æ—Å –∫–∞–∫ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π.\n2. –í—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å —Ä–∞—Å–ø–æ–∑–Ω–∞–ª —Ç–∏–ø –∑–∞–¥–∞—á–∏: {solution.problem_type.value}.\n3. –ü—Ä–æ–≤–µ–¥–µ–Ω—ã —Ä–∞—Å—á–µ—Ç—ã –∏ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω –ø–æ—à–∞–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç.\n---\n*–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Ä–µ—à–µ–Ω–∏–∏: {solution.confidence:.1%} (–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {'‚úì' if solution.verification else '‚úó'})*"""
            else:
                return f"üßÆ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É... –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ. {solution.explanation}"
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≤ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–µ—à–∞—Ç–µ–ª–µ: {e}")
            return f"üßÆ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å —Å—Ç–æ–ª–∫–Ω—É–ª–∞—Å—å —Å –æ—à–∏–±–∫–æ–π –ø—Ä–∏ —Ä–µ—à–µ–Ω–∏–∏ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {e}"
    
    def _solve_physics_neural(self, question):
        """–†–µ—à–∞–µ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ –∑–∞–¥–∞—á–∏"""
        return "‚ö° –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫—É—é –∑–∞–¥–∞—á—É..."
    
    def _explain_electronics_neural(self, question):
        """–û–±—ä—è—Å–Ω—è–µ—Ç —ç–ª–µ–∫—Ç—Ä–æ–Ω–∏–∫—É"""
        return "üîå –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –≤–æ–ø—Ä–æ—Å..."
    
    def _explain_programming_neural(self, question):
        """–û–±—ä—è—Å–Ω—è–µ—Ç –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        return "üíª –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é..."
    
    def _general_response_neural(self, question, category):
        """–û–±—â–∏–π –æ—Ç–≤–µ—Ç"""
        return f"ü§ñ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–ª–∞ –≤–æ–ø—Ä–æ—Å –∫–∞–∫ '{category}' –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç..."

    def _solve_time_series_neural(self, question):
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã.
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –≤–æ–ø—Ä–æ—Å–∞, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç RubinTimeSeriesProcessor –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç.
        """
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤: {question}")

        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞)
        period = 1
        len_in = 1
        price_type = NPriceType.PriceClose # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
        
        # –ü–æ–∏—Å–∫ –ø–µ—Ä–∏–æ–¥–∞
        period_match = re.search(r'–ø–µ—Ä–∏–æ–¥\s*(\d+)', question.lower())
        if period_match:
            period = int(period_match.group(1))

        # –ü–æ–∏—Å–∫ len_in
        len_in_match = re.search(r'–≤—Ö–æ–¥–Ω—ã—Ö\s*–±–∞—Ä–æ–≤\s*(\d+)|len_in\s*(\d+)', question.lower())
        if len_in_match:
            len_in = int(len_in_match.group(1) or len_in_match.group(2))
            
        # –ü–æ–∏—Å–∫ price_type (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å –¥–ª—è –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤)
        if 'high' in question.lower() or '–º–∞–∫—Å–∏–º—É–º' in question.lower():
            price_type = NPriceType.PriceHigh
        elif 'low' in question.lower() or '–º–∏–Ω–∏–º—É–º' in question.lower():
            price_type = NPriceType.PriceLow
        elif 'close' in question.lower() or '–∑–∞–∫—Ä—ã—Ç–∏–µ' in question.lower():
            price_type = NPriceType.PriceClose
            
        # –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–µ —Ç–µ–º, —á—Ç–æ –≤ rubin_time_series_processor.py)
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ —ç—Ç–∏ –¥–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å—Å—è –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
        raw_data = np.array([
            [100, 105, 98, 103, 1000],
            [103, 107, 101, 106, 1200],
            [106, 110, 104, 108, 1100],
            [108, 112, 106, 110, 1300],
            [110, 115, 108, 113, 1500],
            [113, 117, 111, 116, 1400],
            [116, 120, 114, 119, 1600],
            [119, 122, 117, 121, 1700],
            [121, 125, 119, 123, 1800],
            [123, 127, 121, 125, 1900],
        ], dtype=float)

        try:
            self.time_series_processor.set_parameters(
                period=period, 
                price_type=price_type, 
                len_in=len_in,
                koef_tg=10000.0, # –ú–æ–∂–Ω–æ —Ç–æ–∂–µ –ø–∞—Ä—Å–∏—Ç—å –∏–∑ –≤–æ–ø—Ä–æ—Å–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                koef_price=1.0,
                koef_volume=1.0
            )
            
            processed_examples = self.time_series_processor.preprocess_data(raw_data)
            
            if processed_examples:
                # –í—Ä–µ–º–µ–Ω–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∏–∑–≤–µ—Å—Ç–Ω–æ–µ 'output' –∏–∑ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
                # –í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –æ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
                predicted_output_raw = processed_examples[-1]['output'][0] 
                predicted_output = self.time_series_processor.postprocess_output(np.array([predicted_output_raw]))

                response = f"üìä **–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ (–≤—Ä–µ–º–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç):**\n\n"
                response += f"**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:** –ø–µ—Ä–∏–æ–¥={period}, –≤—Ö–æ–¥–Ω—ã—Ö –±–∞—Ä–æ–≤={len_in}, —Ç–∏–ø —Ü–µ–Ω—ã={price_type}\n"
                response += f"**–ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º–æ–µ —Å–ª–µ–¥—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (–≤—Ä–µ–º–µ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑):** {predicted_output:.4f}\n\n"
                response += "**–ü—Ä–æ—Ü–µ—Å—Å:** –î–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω—ã, –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã. " \
                            "(–í—Ä–µ–º–µ–Ω–Ω—ã–π –ø—Ä–æ–≥–Ω–æ–∑ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –ø–æ–∫–∞ –Ω–µ –æ–±—É—á–µ–Ω–∞ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è)"
            else:
                response = "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ä—è–¥—ã —Å –∑–∞–¥–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∏–ª–∏ –¥–∞–Ω–Ω—ã–º–∏."

            return response

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤: {e}")
            return f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤: {e}"
    
    def _solve_physics_neural(self, question):
        """–†–µ—à–µ–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        try:
            logger.info(f"‚ö° –†–µ—à–µ–Ω–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {question}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—à–∞—Ç–µ–ª—å
            result = self.math_solver.solve_problem(question)
            
            if result.problem_type.value == "—Ñ–∏–∑–∏—á–µ—Å–∫–∏–µ_—Ñ–æ—Ä–º—É–ª—ã":
                return f"""‚ö° **–§–ò–ó–ò–ß–ï–°–ö–ò–ô –†–ê–°–ß–ï–¢:**

**–ó–∞–¥–∞—á–∞:** {question}

**–ü–æ—à–∞–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ:**
{chr(10).join([f"{i+1}. {step}" for i, step in enumerate(result.solution_steps)])}

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** {result.final_answer}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}
**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {result.explanation}

*–†–∞—Å—á–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –ø–æ–º–æ—â—å—é —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–∞—Ç–µ–ª—è Rubin AI*"""
            else:
                return f"""‚ö° **–§–ò–ó–ò–ß–ï–°–ö–ê–Ø –ó–ê–î–ê–ß–ê:**

**–ó–∞–¥–∞—á–∞:** {question}

**–°—Ç–∞—Ç—É—Å:** –ó–∞–¥–∞—á–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∫–∞–∫ —Ñ–∏–∑–∏—á–µ—Å–∫–∞—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
**–¢–∏–ø:** {result.problem_type.value}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}

*–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ñ–æ—Ä–º—É–ª*"""
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {e}")
            return f"–û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è —Ñ–∏–∑–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {e}"
    
    def _solve_chemistry_neural(self, question):
        """–†–µ—à–µ–Ω–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–∏—Ö –∑–∞–¥–∞—á —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        try:
            logger.info(f"üß™ –†–µ—à–µ–Ω–∏–µ —Ö–∏–º–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {question}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—à–∞—Ç–µ–ª—å
            result = self.math_solver.solve_problem(question)
            
            if result.problem_type.value == "—Ö–∏–º–∏—á–µ—Å–∫–∏–µ_—Ä–∞—Å—á–µ—Ç—ã":
                return f"""üß™ **–•–ò–ú–ò–ß–ï–°–ö–ò–ô –†–ê–°–ß–ï–¢:**

**–ó–∞–¥–∞—á–∞:** {question}

**–ü–æ—à–∞–≥–æ–≤–æ–µ —Ä–µ—à–µ–Ω–∏–µ:**
{chr(10).join([f"{i+1}. {step}" for i, step in enumerate(result.solution_steps)])}

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** {result.final_answer}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}
**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {result.explanation}

*–†–∞—Å—á–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –ø–æ–º–æ—â—å—é —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–∞—Ç–µ–ª—è Rubin AI*"""
            else:
                return f"""üß™ **–•–ò–ú–ò–ß–ï–°–ö–ê–Ø –ó–ê–î–ê–ß–ê:**

**–ó–∞–¥–∞—á–∞:** {question}

**–°—Ç–∞—Ç—É—Å:** –ó–∞–¥–∞—á–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∫–∞–∫ —Ö–∏–º–∏—á–µ—Å–∫–∞—è, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
**–¢–∏–ø:** {result.problem_type.value}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}

*–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ñ–æ—Ä–º—É–ª*"""
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è —Ö–∏–º–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {e}")
            return f"–û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è —Ö–∏–º–∏—á–µ—Å–∫–æ–π –∑–∞–¥–∞—á–∏: {e}"
    
    def _analyze_graph_neural(self, question):
        """–ê–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        try:
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∏–∫–∞: {question}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—à–∞—Ç–µ–ª—å
            result = self.math_solver.solve_problem(question)
            
            if result.problem_type.value == "–∞–Ω–∞–ª–∏–∑_–≥—Ä–∞—Ñ–∏–∫–æ–≤":
                return f"""üìä **–ê–ù–ê–õ–ò–ó –ì–†–ê–§–ò–ö–ê:**

**–ó–∞–¥–∞—á–∞:** {question}

**–ü–æ—à–∞–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑:**
{chr(10).join([f"{i+1}. {step}" for i, step in enumerate(result.solution_steps)])}

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** {result.final_answer}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}
**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {result.explanation}

*–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω —Å –ø–æ–º–æ—â—å—é —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–∞—Ç–µ–ª—è Rubin AI*"""
            else:
                return f"""üìä **–ê–ù–ê–õ–ò–ó –ì–†–ê–§–ò–ö–ê:**

**–ó–∞–¥–∞—á–∞:** {question}

**–°—Ç–∞—Ç—É—Å:** –ó–∞–¥–∞—á–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∫–∞–∫ –∞–Ω–∞–ª–∏–∑ –≥—Ä–∞—Ñ–∏–∫–∞, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
**–¢–∏–ø:** {result.problem_type.value}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}

*–î–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è OCR –∏ –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è*"""
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä–∞—Ñ–∏–∫–∞: {e}")
            return f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –≥—Ä–∞—Ñ–∏–∫–∞: {e}"
    
    def _create_visualization_neural(self, question):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π —Å –ø–æ–º–æ—â—å—é –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        try:
            logger.info(f"üìà –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {question}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ—à–∞—Ç–µ–ª—å
            result = self.math_solver.solve_problem(question)
            
            if result.problem_type.value == "–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è_–¥–∞–Ω–Ω—ã—Ö":
                return f"""üìà **–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –î–ê–ù–ù–´–•:**

**–ó–∞–¥–∞—á–∞:** {question}

**–ü—Ä–æ—Ü–µ—Å—Å —Å–æ–∑–¥–∞–Ω–∏—è:**
{chr(10).join([f"{i+1}. {step}" for i, step in enumerate(result.solution_steps)])}

**–†–µ–∑—É–ª—å—Ç–∞—Ç:** {result.final_answer}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}
**–û–±—ä—è—Å–Ω–µ–Ω–∏–µ:** {result.explanation}

*–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞ —Å –ø–æ–º–æ—â—å—é —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–∞—Ç–µ–ª—è Rubin AI*"""
            else:
                return f"""üìà **–í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –î–ê–ù–ù–´–•:**

**–ó–∞–¥–∞—á–∞:** {question}

**–°—Ç–∞—Ç—É—Å:** –ó–∞–¥–∞—á–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ –∫–∞–∫ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö, –Ω–æ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
**–¢–∏–ø:** {result.problem_type.value}
**–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å:** {result.confidence:.1%}

*–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤ —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥—É–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö*"""
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")
            return f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}"

    def _load_training_data(self, training_file: str) -> List[Dict[str, Any]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–∑ JSONL-—Ñ–∞–π–ª–∞.
        """
        training_data = []
        if os.path.exists(training_file):
            with open(training_file, 'r', encoding='utf-8') as f:
                for line in f:
                    try:
                        data = json.loads(line)
                        training_data.append(data)
                    except json.JSONDecodeError as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Ñ–∞–π–ª–µ {training_file}: {e} - —Å—Ç—Ä–æ–∫–∞: {line.strip()}")
        else:
            logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –æ–±—É—á–µ–Ω–∏—è {training_file} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        return training_data

    def learn_from_feedback(self, question, correct_category, user_rating):
        """–û–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏"""
        try:
            logger.info(f"üìö –û–±—É—á–µ–Ω–∏–µ: {question} -> {correct_category} (—Ä–µ–π—Ç–∏–Ω–≥: {user_rating})")
            
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
            # –ù–∞–ø—Ä–∏–º–µ—Ä, fine-tuning –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            training_data = {
                'timestamp': datetime.now().isoformat(),
                'question': question,
                'correct_category': correct_category,
                'user_rating': user_rating
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ñ–∞–π–ª –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö
            with open('neural_training_data.jsonl', 'a', encoding='utf-8') as f:
                f.write(json.dumps(training_data, ensure_ascii=False) + '\n')
            
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False
    
    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–æ–¥–µ–ª—å"""
        try:
            if self.neural_network:
                torch.save(self.neural_network.state_dict(), 'rubin_neural_model.pth')
                logger.info("üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å"""
        try:
            if os.path.exists('rubin_neural_model.pth') and self.neural_network:
                self.neural_network.load_state_dict(torch.load('rubin_neural_model.pth'))
                logger.info("üìÇ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")

    def _prepare_training_data(self, training_data, normalize_embeddings: bool = True) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor]]:
        """
        –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏.
        """
        try:
            questions = []
            categories = []
            for data in training_data:
                questions.append(data['question'])
                categories.append(data['correct_category'])

            if not questions:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –û–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
                return None, None

            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –≤ —á–∏—Å–ª–æ–≤—ã–µ –º–µ—Ç–∫–∏
            category_to_idx = {cat: i for i, cat in enumerate(self.categories)}
            numerical_labels = [category_to_idx.get(cat, len(self.categories) - 1) for cat in categories] # Fallback to '–¥—Ä—É–≥–æ–µ'

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
            logger.info("üîÑ –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
            embeddings = self.sentence_model.encode(questions, convert_to_numpy=True)
            embeddings_tensor = torch.FloatTensor(embeddings).to(self.device)
            labels_tensor = torch.LongTensor(numerical_labels).to(self.device)

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø–µ—Ä–µ–¥ –ø–æ–¥–∞—á–µ–π –≤ –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å
            if normalize_embeddings:
                # –î–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–∏–Ω–µ–π–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
                min_val = embeddings_tensor.min()
                max_val = embeddings_tensor.max()
                if min_val == max_val: # –ò–∑–±–µ–≥–∞–µ–º –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å, –µ—Å–ª–∏ –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ–¥–∏–Ω–∞–∫–æ–≤—ã
                    logger.warning("‚ö†Ô∏è –í—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–º–µ—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é.")
                else:
                    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –¥–ª—è —Ç–µ–Ω–∑–æ—Ä–∞ PyTorch, –∏—Å–ø–æ–ª—å–∑—É—è .cpu() –¥–ª—è NumPy-–æ–ø–µ—Ä–∞—Ü–∏–π
                    # –∏ .to(self.device) –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è PyTorch
                    normalized_np = self.data_preprocessor.linear_normalization(embeddings_tensor.cpu().numpy(), min_val.item(), max_val.item())
                    embeddings_tensor = torch.FloatTensor(normalized_np).to(self.device)

            return embeddings_tensor, labels_tensor
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, None

    def train_neural_network(self, training_file='neural_training_data.jsonl', num_epochs=10, learning_rate=0.001, weight_decay=0.01, log_file_path: Optional[str] = "training_log.csv", normalize_embeddings: bool = True):
        """
        –û–±—É—á–∞–µ—Ç –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏.
        –í–∫–ª—é—á–∞–µ—Ç L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é (weight_decay) –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç Dropout (—É–∂–µ –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ).
        """
        if not ML_AVAILABLE or not self.neural_network or not self.sentence_model:
            logger.warning("‚ö†Ô∏è –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏–ª–∏ SentenceTransformer –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
            return

        try:
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            training_data = self._load_training_data(training_file)
            if not training_data:
                logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –û–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
                return

            # 2. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–≤—ã–∑—ã–≤–∞–µ–º –Ω–æ–≤—ã–π –º–µ—Ç–æ–¥)
            embeddings_tensor, labels_tensor = self._prepare_training_data(training_data, normalize_embeddings=normalize_embeddings)

            if embeddings_tensor is None or labels_tensor is None:
                logger.error("‚ùå –û—à–∏–±–∫–∞: –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
                return

            # 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.Adam(self.neural_network.parameters(), lr=learning_rate, weight_decay=weight_decay) # L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è

            # 3. –¶–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è
            self.neural_network.train() # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å–µ—Ç—å –≤ —Ä–µ–∂–∏–º –æ–±—É—á–µ–Ω–∏—è (–∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç Dropout)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è CSV-–ª–æ–≥–∞
            if log_file_path:
                with open(log_file_path, 'w', newline='', encoding='utf-8') as csvfile:
                    csv_writer = csv.writer(csvfile)
                    csv_writer.writerow(['Epoch', 'Loss'])
            
            for epoch in range(num_epochs):
                optimizer.zero_grad()
                outputs = self.neural_network(embeddings_tensor)
                loss = criterion(outputs, labels_tensor)
                loss.backward()
                optimizer.step()

                logger.info(f'–≠–ø–æ—Ö–∞ [{epoch+1}/{num_epochs}], –ü–æ—Ç–µ—Ä–∏: {loss.item():.4f}')
                
                # –ó–∞–ø–∏—Å—å –≤ CSV-–ª–æ–≥
                if log_file_path:
                    with open(log_file_path, 'a', newline='', encoding='utf-8') as csvfile:
                        csv_writer = csv.writer(csvfile)
                        csv_writer.writerow([epoch + 1, f'{loss.item():.4f}'])

            self.neural_network.eval() # –ü–µ—Ä–µ–≤–æ–¥–∏–º —Å–µ—Ç—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ (–æ—Ç–∫–ª—é—á–∞–µ—Ç Dropout)
            self.save_model()
            logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.")

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏: {e}")

    def get_neural_stats(self):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
        return {
            'device': str(self.device),
            'neural_network_active': self.neural_network is not None,
            'sentence_model_active': self.sentence_model is not None,
            'categories': self.categories,
            'conversation_count': len(self.conversation_history),
            'model_parameters': sum(p.numel() for p in self.neural_network.parameters()) if self.neural_network else 0
        }

def plot_training_history(log_file_path: str = "training_log.csv"):
    """–°—Ç—Ä–æ–∏—Ç –≥—Ä–∞—Ñ–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –∏–∑ CSV-—Ñ–∞–π–ª–∞."""
    epochs = []
    losses = []
    
    if not os.path.exists(log_file_path):
        logger.warning(f"‚ö†Ô∏è –§–∞–π–ª –ª–æ–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è {log_file_path} –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞.")
        return

    try:
        with open(log_file_path, 'r', encoding='utf-8') as csvfile:
            csv_reader = csv.reader(csvfile)
            header = next(csv_reader) # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            for row in csv_reader:
                if len(row) == 2:
                    epochs.append(int(row[0]))
                    losses.append(float(row[1]))

        if not epochs:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –≤ —Ñ–∞–π–ª–µ –ª–æ–≥–æ–≤.")
            return

        plt.figure(figsize=(10, 6))
        plt.plot(epochs, losses, marker='o', linestyle='-', color='blue')
        plt.title('–ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏')
        plt.xlabel('–≠–ø–æ—Ö–∞')
        plt.ylabel('–ü–æ—Ç–µ—Ä–∏ (Loss)')
        plt.grid(True)
        plt.show()
        logger.info("‚úÖ –ì—Ä–∞—Ñ–∏–∫ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω.")

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –≥—Ä–∞—Ñ–∏–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –æ–±—É—á–µ–Ω–∏—è: {e}")

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
neural_rubin = None

def get_neural_rubin():
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏"""
    global neural_rubin
    if neural_rubin is None:
        neural_rubin = NeuralRubinAI()
    return neural_rubin

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ Rubin AI v2 –≤ —Ç–µ—Å—Ç–æ–≤–æ–º —Ä–µ–∂–∏–º–µ")
    ai = get_neural_rubin()

    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≥–∏–±–∫–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π –∞–∫—Ç–∏–≤–∞—Ü–∏–∏
    print("\nüß† –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ì–ò–ë–ö–ò–• –§–£–ù–ö–¶–ò–ô –ê–ö–¢–ò–í–ê–¶–ò–ò")
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    # –ü–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è neural_network –≤ ai –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
    ai.neural_network = RubinNeuralNetwork(
        input_size=384,
        hidden_sizes=[256, 128, 64],
        num_classes=len(ai.categories),
        activations=['Tanh', 'ReLU', 'Softsign'], # –ü—Ä–∏–º–µ—Ä —Ä–∞–∑–Ω—ã—Ö –∞–∫—Ç–∏–≤–∞—Ü–∏–π
        dropout_rates=[0.1, 0.1] # –ü—Ä–∏–º–µ—Ä –¥—Ä—É–≥–∏—Ö dropout rates
    ).to(ai.device)
    logger.info(f"‚úÖ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ —Å –≥–∏–±–∫–∏–º–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏—è–º–∏. –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {ai.neural_network.encoder}")

    # –ü—Ä–æ–≤–æ–¥–∏–º –æ–±—É—á–µ–Ω–∏–µ —Å –Ω–æ–≤—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
    print("\nüìö –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –û–ë–£–ß–ï–ù–ò–Ø –° –ù–û–í–´–ú–ò –ê–ö–¢–ò–í–ê–¶–ò–Ø–ú–ò")
    training_file = 'neural_training_data.jsonl'
    if not os.path.exists(training_file):
        with open(training_file, 'w', encoding='utf-8') as f:
            f.write(json.dumps({'question': '2+2', 'correct_category': '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞', 'user_rating': 5}, ensure_ascii=False) + '\n')
            f.write(json.dumps({'question': '–ß—Ç–æ —Ç–∞–∫–æ–µ —Ç—Ä–∞–Ω–∑–∏—Å—Ç–æ—Ä?', 'correct_category': '—ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞', 'user_rating': 5}, ensure_ascii=False) + '\n')
            f.write(json.dumps({'question': '–†–µ—à–∏ 5*10', 'correct_category': '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞', 'user_rating': 5}, ensure_ascii=False) + '\n')
            f.write(json.dumps({'question': '–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç for loop –≤ python?', 'correct_category': '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', 'user_rating': 5}, ensure_ascii=False) + '\n')

    ai.train_neural_network(num_epochs=5, learning_rate=0.01, log_file_path="training_log.csv") # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∏–º—è —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤
    plot_training_history(log_file_path="training_log.csv") # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ –∏–º—è —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤

    print("\n‚ùì –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ì–ï–ù–ï–†–ê–¶–ò–ò –û–¢–í–ï–¢–û–í –° –í–ï–ö–¢–û–†–ù–´–ú –ü–û–ò–°–ö–û–ú –ò –ù–û–í–´–ú–ò –í–û–ó–ú–û–ñ–ù–û–°–¢–Ø–ú–ò")
    test_questions = [
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –∫–≤–∞–Ω—Ç–æ–≤–∞—è —Ñ–∏–∑–∏–∫–∞?",
        "–†–µ—à–∏ —É—Ä–∞–≤–Ω–µ–Ω–∏–µ 2x + 5 = 11",
        "–ù–∞–ø–∏—à–∏ –ø—Ä–æ–≥—Ä–∞–º–º—É –Ω–∞ Python, –∫–æ—Ç–æ—Ä–∞—è –≤—ã–≤–æ–¥–∏—Ç Hello, World!",
        "–ö–∞–∫–æ–µ —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏–µ —Ä–µ–∑–∏—Å—Ç–æ—Ä–∞, –µ—Å–ª–∏ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ 12–í –∏ —Ç–æ–∫ 2–ê?",
        "–î–∞–π –ø—Ä–æ–≥–Ω–æ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ —Å –ø–µ—Ä–∏–æ–¥–æ–º 3 –∏ 2 –≤—Ö–æ–¥–Ω—ã—Ö –±–∞—Ä–∞ –¥–ª—è —Ü–µ–Ω—ã –∑–∞–∫—Ä—ã—Ç–∏—è.", # –¢–µ—Å—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤
        "–ö–∞–∫–∏–µ –±—ã–≤–∞—é—Ç –≤–∏–¥—ã —Ä–µ–∞–∫—Ç–æ—Ä–æ–≤?"
    ]

    for question in test_questions:
        print(f"\n‚ùì –í–æ–ø—Ä–æ—Å: {question}")
        response = ai.generate_response(question)
        print(f"ü§ñ –û—Ç–≤–µ—Ç: {response['response']}")
        print(f"üìÇ –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {response['category']}")
        print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {response['confidence']:.1%}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = ai.get_neural_stats()
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ù–ï–ô–†–û–ù–ù–û–ô –°–ï–¢–ò:")
    print(f"‚Ä¢ –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {stats['device']}")
    print(f"‚Ä¢ –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∞–∫—Ç–∏–≤–Ω–∞: {stats['neural_network_active']}")
    print(f"‚Ä¢ –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤ –º–æ–¥–µ–ª–∏: {stats['model_parameters']:,}")
    print(f"‚Ä¢ –î–∏–∞–ª–æ–≥–æ–≤: {stats['conversation_count']}")