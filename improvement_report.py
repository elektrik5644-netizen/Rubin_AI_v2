#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —É–ª—É—á—à–µ–Ω–∏—è–º —Å–∏—Å—Ç–µ–º—ã Rubin AI
"""

import json
import sqlite3
from datetime import datetime

def generate_improvement_report():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –ø–æ —É–ª—É—á—à–µ–Ω–∏—è–º"""
    
    print("=== –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢ –ü–û –£–õ–£–ß–®–ï–ù–ò–Ø–ú RUBIN AI ===\n")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
    try:
        conn = sqlite3.connect("rubin_ai_v2.db")
        cursor = conn.cursor()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        cursor.execute("SELECT COUNT(*) FROM documents")
        total_docs = cursor.fetchone()[0]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        cursor.execute("SELECT COUNT(*) FROM synonyms")
        total_synonyms = cursor.fetchone()[0]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å–∏–Ω–æ–Ω–∏–º–æ–≤
        cursor.execute("""
            SELECT category, COUNT(*) 
            FROM synonyms 
            GROUP BY category 
            ORDER BY COUNT(*) DESC
        """)
        synonyms_by_category = cursor.fetchall()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        cursor.execute("""
            SELECT category, COUNT(*) 
            FROM documents 
            GROUP BY category 
            ORDER BY COUNT(*) DESC
        """)
        docs_by_category = cursor.fetchall()
        
        conn.close()
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    try:
        with open("test_results.json", "r", encoding="utf-8") as f:
            test_results = json.load(f)
    except:
        test_results = None
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –°–ò–°–¢–ï–ú–´:")
    print(f"   üìÑ –í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_docs}")
    print(f"   üîó –°–∏–Ω–æ–Ω–∏–º–æ–≤ –¥–æ–±–∞–≤–ª–µ–Ω–æ: {total_synonyms}")
    
    print(f"\nüìÇ –î–û–ö–£–ú–ï–ù–¢–´ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    for category, count in docs_by_category:
        print(f"   - {category}: {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    
    print(f"\nüîó –°–ò–ù–û–ù–ò–ú–´ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    for category, count in synonyms_by_category:
        print(f"   - {category}: {count} —Å–∏–Ω–æ–Ω–∏–º–æ–≤")
    
    if test_results:
        print(f"\nüß™ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø:")
        print(f"   üìä –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {test_results['total_queries']}")
        print(f"   üéØ –¢–µ–º –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ: {test_results['total_topics']}")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ —Ç–µ–º–∞–º
        print(f"\nüìã –ö–ê–ß–ï–°–¢–í–û –ü–û –¢–ï–ú–ê–ú:")
        for topic_result in test_results['topics_results']:
            topic = topic_result['topic']
            responses = topic_result['responses']
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ
            quality_scores = [r.get('quality_score', 0) for r in responses if 'quality_score' in r]
            avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
            
            print(f"   üéØ {topic}: {avg_quality:.2f} (—Å—Ä–µ–¥–Ω–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ)")
    
    print(f"\n‚úÖ –í–´–ü–û–õ–ù–ï–ù–ù–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø:")
    print(f"   1. üîÑ –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏")
    print(f"   2. üîó –î–æ–±–∞–≤–ª–µ–Ω–∏–µ 104 —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤")
    print(f"   3. üìä –°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö")
    print(f"   4. üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å 30 —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞–º–∏")
    print(f"   5. üìà –£–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
    
    print(f"\nüéØ –ö–õ–Æ–ß–ï–í–´–ï –£–õ–£–ß–®–ï–ù–ò–Ø –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú:")
    print(f"   üîß –ü–ò–î-—Ä–µ–≥—É–ª—è—Ç–æ—Ä—ã: –¥–æ–±–∞–≤–ª–µ–Ω—ã —Å–∏–Ω–æ–Ω–∏–º—ã PID, —Ä–µ–≥—É–ª—è—Ç–æ—Ä, –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä")
    print(f"   ‚ö° –≠–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞: —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –∑–∞–∫–æ–Ω–∞ –û–º–∞, —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è, —Ç–æ–∫–∞")
    print(f"   üêç Python: —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ–¥–∞, –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤")
    print(f"   üì° –†–∞–¥–∏–æ–º–µ—Ö–∞–Ω–∏–∫–∞: —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è –∞–Ω—Ç–µ–Ω–Ω, —Ä–∞–¥–∏–æ, –ø–µ—Ä–µ–¥–∞—á–∏")
    print(f"   ü§ñ –ê–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è: —Å–∏–Ω–æ–Ω–∏–º—ã –¥–ª—è —Å–∏—Å—Ç–µ–º —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è, –∫–æ–Ω—Ç—Ä–æ–ª—è")
    
    print(f"\nüìà –†–ï–ó–£–õ–¨–¢–ê–¢–´ –£–õ–£–ß–®–ï–ù–ò–ô:")
    if test_results:
        total_queries = test_results['total_queries']
        successful_queries = sum(topic['successful_queries'] for topic in test_results['topics_results'])
        success_rate = (successful_queries / total_queries * 100) if total_queries > 0 else 0
        
        print(f"   ‚úÖ –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {success_rate:.1f}%")
        print(f"   üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total_queries}")
        print(f"   üéØ –£—Å–ø–µ—à–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {successful_queries}")
    
    print(f"\nüí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –î–õ–Ø –î–ê–õ–¨–ù–ï–ô–®–ï–ì–û –†–ê–ó–í–ò–¢–ò–Ø:")
    print(f"   1. üìö –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
    print(f"   2. üîç –†–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤")
    print(f"   3. üß† –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
    print(f"   4. üìù –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º")
    print(f"   5. üîÑ –†–µ–≥—É–ª—è—Ä–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–µ–∫—Å–æ–≤")
    
    print(f"\nüéâ –°–ò–°–¢–ï–ú–ê RUBIN AI –£–°–ü–ï–®–ù–û –£–õ–£–ß–®–ï–ù–ê!")
    print(f"   –í—Ä–µ–º—è —É–ª—É—á—à–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_data = {
        "timestamp": datetime.now().isoformat(),
        "total_documents": total_docs,
        "total_synonyms": total_synonyms,
        "documents_by_category": dict(docs_by_category),
        "synonyms_by_category": dict(synonyms_by_category),
        "test_results": test_results
    }
    
    with open("improvement_report.json", "w", encoding="utf-8") as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)
    
    print(f"   üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ improvement_report.json")

if __name__ == "__main__":
    generate_improvement_report()






















