#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ethical Core Server - –≠—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é
–ü–æ—Ä—Ç: 8105
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import time
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
import numpy as np
from collections import defaultdict, Counter
import threading

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏
try:
    from neural_rubin import get_neural_rubin
    NEURAL_NETWORK_AVAILABLE = True
    logger = logging.getLogger(__name__)
    logger.info("üß† –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ Ethical Core!")
except ImportError as e:
    NEURAL_NETWORK_AVAILABLE = False
    logger = logging.getLogger(__name__)
    logger.warning(f"‚ö†Ô∏è –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –≤ Ethical Core: {e}")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app, origins="*", methods=["GET", "POST", "OPTIONS"], allow_headers=["Content-Type", "Authorization"])

# –≠—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã –∏ –ø—Ä–∞–≤–∏–ª–∞
ETHICAL_PRINCIPLES = {
    'fairness': {
        'name': '–°–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å',
        'description': '–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ —Ä–∞–≤–Ω–æ–≥–æ –∏ —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ–≥–æ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫–æ –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º',
        'rules': [
            '–ù–µ –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ –ø–æ–ª—É, –≤–æ–∑—Ä–∞—Å—Ç—É, —Ä–∞—Å–µ, —Ä–µ–ª–∏–≥–∏–∏',
            '–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å —Ä–∞–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –≤—Å–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º',
            '–ò–∑–±–µ–≥–∞—Ç—å –ø—Ä–µ–¥–≤–∑—è—Ç–æ—Å—Ç–∏ –≤ –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö'
        ]
    },
    'transparency': {
        'name': '–ü—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å',
        'description': '–û—Ç–∫—Ä—ã—Ç–æ—Å—Ç—å –∏ –ø–æ–Ω—è—Ç–Ω–æ—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π',
        'rules': [
            '–û–±—ä—è—Å–Ω—è—Ç—å –ª–æ–≥–∏–∫—É –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π',
            '–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–∞–Ω–Ω—ã—Ö –∏ –∞–ª–≥–æ—Ä–∏—Ç–º–∞—Ö',
            '–ë—ã—Ç—å —á–µ—Å—Ç–Ω—ã–º –æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è—Ö —Å–∏—Å—Ç–µ–º—ã'
        ]
    },
    'privacy': {
        'name': '–ö–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å',
        'description': '–ó–∞—â–∏—Ç–∞ –ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π',
        'rules': [
            '–ú–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å–±–æ—Ä –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö',
            '–ó–∞—â–∏—â–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –æ—Ç –Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞',
            '–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∫–æ–Ω—Ç—Ä–æ–ª—å –Ω–∞–¥ –¥–∞–Ω–Ω—ã–º–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º'
        ]
    },
    'safety': {
        'name': '–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å',
        'description': '–û–±–µ—Å–ø–µ—á–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ —Å–∏—Å—Ç–µ–º—ã',
        'rules': [
            '–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞—Ç—å –≤—Ä–µ–¥–Ω—ã–µ –∏–ª–∏ –æ–ø–∞—Å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è',
            '–ó–∞—â–∏—â–∞—Ç—å –æ—Ç –∑–ª–æ—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–π',
            '–û–±–µ—Å–ø–µ—á–∏–≤–∞—Ç—å –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å —Å–∏—Å—Ç–µ–º—ã'
        ]
    },
    'accountability': {
        'name': '–û—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å',
        'description': '–ü—Ä–∏–Ω—è—Ç–∏–µ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –∑–∞ –¥–µ–π—Å—Ç–≤–∏—è —Å–∏—Å—Ç–µ–º—ã',
        'rules': [
            '–ë—ã—Ç—å –≥–æ—Ç–æ–≤—ã–º –æ–±—ä—è—Å–Ω–∏—Ç—å —Ä–µ—à–µ–Ω–∏—è',
            '–ò—Å–ø—Ä–∞–≤–ª—è—Ç—å –æ—à–∏–±–∫–∏ –∏ –Ω–µ–¥–æ—á–µ—Ç—ã',
            '–£—á–∏—Ç—ã–≤–∞—Ç—å –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π'
        ]
    }
}

# –≠—Ç–∏—á–µ—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
ETHICAL_CATEGORIES = [
    '–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å', '–∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç—å', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å', 
    '–ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç—å', '–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å', '—ç—Ç–∏–∫–∞', '–º–æ—Ä–∞–ª—å',
    '–ø—Ä–∞–≤–∞', '—Å–≤–æ–±–æ–¥–∞', '—Ä–∞–≤–µ–Ω—Å—Ç–≤–æ', '—á–µ—Å—Ç–Ω–æ—Å—Ç—å', '–¥–æ–≤–µ—Ä–∏–µ'
]

class EthicalAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    
    def __init__(self):
        self.ethical_violations = []
        self.ethical_scores = defaultdict(list)
        self.analysis_history = []
        self.neural_ai = None
        
        if NEURAL_NETWORK_AVAILABLE:
            try:
                self.neural_ai = get_neural_rubin()
                logger.info("üß† –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –≤ Ethical Analyzer")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏: {e}")
    
    def analyze_request(self, request_text: str, user_context: Dict = None) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞"""
        start_time = time.time()
        
        try:
            # –ë–∞–∑–æ–≤—ã–π —ç—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
            ethical_analysis = self._basic_ethical_analysis(request_text)
            
            # –ù–µ–π—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            if self.neural_ai:
                neural_analysis = self._neural_ethical_analysis(request_text)
                ethical_analysis.update(neural_analysis)
            
            # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            if user_context:
                context_analysis = self._contextual_ethical_analysis(request_text, user_context)
                ethical_analysis.update(context_analysis)
            
            # –†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–æ—Ä–∞
            ethical_score = self._calculate_ethical_score(ethical_analysis)
            ethical_analysis['overall_score'] = ethical_score
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
            recommendations = self._generate_recommendations(ethical_analysis)
            ethical_analysis['recommendations'] = recommendations
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞
            processing_time = time.time() - start_time
            self._log_analysis(request_text, ethical_analysis, processing_time)
            
            return {
                'success': True,
                'ethical_analysis': ethical_analysis,
                'processing_time': processing_time,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _basic_ethical_analysis(self, text: str) -> Dict[str, Any]:
        """–ë–∞–∑–æ–≤—ã–π —ç—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        text_lower = text.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        problematic_keywords = [
            '–≤–∑–ª–æ–º–∞—Ç—å', '–≤–∑–ª–æ–º', '—Ö–∞–∫', '–æ–±–º–∞–Ω', '–º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ',
            '–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è', '—Ä–∞—Å–∏–∑–º', '—Å–µ–∫—Å–∏–∑–º', '–Ω–µ–Ω–∞–≤–∏—Å—Ç—å',
            '–Ω–∞—Å–∏–ª–∏–µ', '–æ—Ä—É–∂–∏–µ', '–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏', '—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º'
        ]
        
        violations = []
        for keyword in problematic_keywords:
            if keyword in text_lower:
                violations.append({
                    'type': 'problematic_content',
                    'keyword': keyword,
                    'severity': 'high' if keyword in ['—Ç–µ—Ä—Ä–æ—Ä–∏–∑–º', '–Ω–∞—Å–∏–ª–∏–µ', '–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏'] else 'medium'
                })
        
        # –ê–Ω–∞–ª–∏–∑ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
        category_scores = {}
        for category in ETHICAL_CATEGORIES:
            if category in text_lower:
                category_scores[category] = 0.8
            else:
                category_scores[category] = 0.3
        
        return {
            'violations': violations,
            'category_scores': category_scores,
            'text_length': len(text),
            'complexity': 'high' if len(text) > 100 else 'medium' if len(text) > 50 else 'low'
        }
    
    def _neural_ethical_analysis(self, text: str) -> Dict[str, Any]:
        """–ù–µ–π—Ä–æ–Ω–Ω—ã–π —ç—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–π—Ä–æ–Ω–Ω—É—é —Å–µ—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            category, confidence = self.neural_ai.classify_question(text)
            
            # –ê–Ω–∞–ª–∏–∑ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            ethical_aspects = {
                'neural_category': category,
                'neural_confidence': confidence,
                'ethical_relevance': self._assess_ethical_relevance(category, text)
            }
            
            return ethical_aspects
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–µ–π—Ä–æ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {'neural_error': str(e)}
    
    def _assess_ethical_relevance(self, category: str, text: str) -> Dict[str, float]:
        """–û—Ü–µ–Ω–∫–∞ —ç—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        relevance_scores = {}
        
        # –ú–∞–ø–ø–∏–Ω–≥ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ —ç—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã
        category_ethical_map = {
            '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ': {'transparency': 0.8, 'safety': 0.7},
            '—ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞': {'safety': 0.9, 'transparency': 0.6},
            '–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞': {'fairness': 0.7, 'transparency': 0.8},
            '—Ñ–∏–∑–∏–∫–∞': {'safety': 0.8, 'transparency': 0.7},
            '–æ–±—â–∏–µ_–≤–æ–ø—Ä–æ—Å—ã': {'fairness': 0.6, 'privacy': 0.5}
        }
        
        if category in category_ethical_map:
            relevance_scores = category_ethical_map[category]
        else:
            # –ë–∞–∑–æ–≤—ã–µ –æ—Ü–µ–Ω–∫–∏ –¥–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            relevance_scores = {
                'fairness': 0.5,
                'transparency': 0.5,
                'privacy': 0.5,
                'safety': 0.5,
                'accountability': 0.5
            }
        
        return relevance_scores
    
    def _contextual_ethical_analysis(self, text: str, context: Dict) -> Dict[str, Any]:
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π —ç—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"""
        context_analysis = {}
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if 'user_id' in context:
            context_analysis['user_tracking'] = 'enabled'
            context_analysis['privacy_concern'] = 'medium'
        
        if 'location' in context:
            context_analysis['location_tracking'] = 'enabled'
            context_analysis['privacy_concern'] = 'high'
        
        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        current_hour = datetime.now().hour
        if current_hour < 6 or current_hour > 22:
            context_analysis['unusual_time'] = True
            context_analysis['safety_concern'] = 'low'
        
        return context_analysis
    
    def _calculate_ethical_score(self, analysis: Dict) -> float:
        """–†–∞—Å—á–µ—Ç –æ–±—â–µ–≥–æ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–æ—Ä–∞"""
        base_score = 0.8  # –ë–∞–∑–æ–≤—ã–π —Å–∫–æ—Ä
        
        # –®—Ç—Ä–∞—Ñ—ã –∑–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è
        violations = analysis.get('violations', [])
        for violation in violations:
            if violation['severity'] == 'high':
                base_score -= 0.3
            elif violation['severity'] == 'medium':
                base_score -= 0.1
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ —ç—Ç–∏—á–µ—Å–∫–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        category_scores = analysis.get('category_scores', {})
        ethical_bonus = sum(category_scores.values()) / len(category_scores) * 0.1
        base_score += ethical_bonus
        
        # –ù–µ–π—Ä–æ–Ω–Ω—ã–π –±–æ–Ω—É—Å
        if 'neural_confidence' in analysis:
            neural_bonus = analysis['neural_confidence'] * 0.1
            base_score += neural_bonus
        
        return max(0.0, min(1.0, base_score))
    
    def _generate_recommendations(self, analysis: Dict) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—Ä—É—à–µ–Ω–∏–π
        violations = analysis.get('violations', [])
        if violations:
            recommendations.append("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤ –∑–∞–ø—Ä–æ—Å–µ")
            recommendations.append("üîç –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ—Ä–∞
        overall_score = analysis.get('overall_score', 0.5)
        if overall_score < 0.6:
            recommendations.append("üìã –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å–º–æ—Ç—Ä–µ—Ç—å —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫—É –∑–∞–ø—Ä–æ—Å–∞")
            recommendations.append("ü§ù –£–±–µ–¥–∏—Ç–µ—Å—å –≤ —Å–æ–±–ª—é–¥–µ–Ω–∏–∏ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤")
        elif overall_score > 0.8:
            recommendations.append("‚úÖ –ó–∞–ø—Ä–æ—Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —ç—Ç–∏—á–µ—Å–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º")
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if 'privacy_concern' in analysis:
            if analysis['privacy_concern'] == 'high':
                recommendations.append("üîí –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏ - –º–∏–Ω–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –¥–∞–Ω–Ω—ã–µ")
        
        if 'safety_concern' in analysis:
            recommendations.append("üõ°Ô∏è –£—á–∏—Ç—ã–≤–∞–π—Ç–µ –∞—Å–ø–µ–∫—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        return recommendations
    
    def _log_analysis(self, text: str, analysis: Dict, processing_time: float):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'text_length': len(text),
            'overall_score': analysis.get('overall_score', 0),
            'violations_count': len(analysis.get('violations', [])),
            'processing_time': processing_time,
            'neural_used': 'neural_confidence' in analysis
        }
        
        self.analysis_history.append(log_entry)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if len(self.analysis_history) > 1000:
            self.analysis_history = self.analysis_history[-500:]

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
ethical_analyzer = EthicalAnalyzer()

# CORS –æ–±—Ä–∞–±–æ—Ç–∫–∞
@app.before_request
def handle_preflight():
    if request.method == "OPTIONS":
        response = jsonify({})
        response.headers.add("Access-Control-Allow-Origin", "*")
        response.headers.add('Access-Control-Allow-Headers', "Content-Type,Authorization")
        response.headers.add('Access-Control-Allow-Methods', "GET,POST,OPTIONS")
        response.headers.add('Content-Type', 'application/json; charset=utf-8')
        return response

@app.after_request
def after_request(response):
    if response.content_type and 'application/json' in response.content_type:
        response.headers['Content-Type'] = 'application/json; charset=utf-8'
    return response

@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ Ethical Core"""
    return jsonify({
        'name': 'Ethical Core Server',
        'version': '2.0',
        'status': 'online',
        'neural_network': 'available' if NEURAL_NETWORK_AVAILABLE else 'unavailable',
        'port': 8105,
        'ethical_principles': list(ETHICAL_PRINCIPLES.keys()),
        'description': '–≠—Ç–∏—á–µ—Å–∫–∏–π –º–æ–¥—É–ª—å —Å –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç—å—é –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è —ç—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–æ–≤'
    })

@app.route('/api/ethical/analyze', methods=['POST'])
def analyze_ethical():
    """–ê–Ω–∞–ª–∏–∑ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–æ–≤ –∑–∞–ø—Ä–æ—Å–∞"""
    try:
        data = request.get_json()
        request_text = data.get('text', '').strip()
        user_context = data.get('context', {})
        
        if not request_text:
            return jsonify({
                'success': False,
                'error': '–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'
            }), 400
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —ç—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑
        result = ethical_analyzer.analyze_request(request_text, user_context)
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ analyze_ethical: {e}")
        return jsonify({
            'success': False,
            'error': f'–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}'
        }), 500

@app.route('/api/ethical/principles')
def get_principles():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤"""
    return jsonify({
        'success': True,
        'principles': ETHICAL_PRINCIPLES,
        'categories': ETHICAL_CATEGORIES
    })

@app.route('/api/ethical/history')
def get_analysis_history():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∞–Ω–∞–ª–∏–∑–æ–≤"""
    recent_history = ethical_analyzer.analysis_history[-50:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 –∑–∞–ø–∏—Å–µ–π
    
    return jsonify({
        'success': True,
        'history': recent_history,
        'total_analyses': len(ethical_analyzer.analysis_history)
    })

@app.route('/api/ethical/stats')
def get_ethical_stats():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —ç—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    history = ethical_analyzer.analysis_history
    
    if not history:
        return jsonify({
            'success': True,
            'stats': {
                'total_analyses': 0,
                'avg_score': 0,
                'avg_processing_time': 0
            }
        })
    
    # –†–∞—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    scores = [entry['overall_score'] for entry in history]
    processing_times = [entry['processing_time'] for entry in history]
    
    stats = {
        'total_analyses': len(history),
        'avg_score': np.mean(scores) if scores else 0,
        'min_score': np.min(scores) if scores else 0,
        'max_score': np.max(scores) if scores else 0,
        'avg_processing_time': np.mean(processing_times) if processing_times else 0,
        'neural_usage_rate': sum(1 for entry in history if entry.get('neural_used', False)) / len(history) * 100
    }
    
    return jsonify({
        'success': True,
        'stats': stats
    })

@app.route('/api/health')
def health():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞"""
    return jsonify({
        'status': 'healthy',
        'timestamp': time.time(),
        'neural_network': NEURAL_NETWORK_AVAILABLE,
        'ethical_analyzer': 'active',
        'port': 8105
    })

if __name__ == '__main__':
    logger.info("üöÄ Ethical Core Server –∑–∞–ø—É—â–µ–Ω")
    logger.info("URL: http://localhost:8105")
    logger.info("üß† –ù–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å: " + ("–¥–æ—Å—Ç—É–ø–Ω–∞" if NEURAL_NETWORK_AVAILABLE else "–Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"))
    logger.info("üìã –≠—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã: " + ", ".join(ETHICAL_PRINCIPLES.keys()))
    
    app.run(host='0.0.0.0', port=8105, debug=False)