#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è –≤ –æ—Å–Ω–æ–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É Rubin AI
"""

import sqlite3
import json
import re
from typing import List, Dict, Tuple, Set
from datetime import datetime
import os
import sys

class RubinAIVocabularyIntegration:
    """–ö–ª–∞—Å—Å –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å–ª–æ–≤–∞—Ä—è –≤ Rubin AI"""
    
    def __init__(self, db_path: str = "rubin_ai_v2.db"):
        self.db_path = db_path
        self.connection = None
        self.connect_database()
    
    def connect_database(self):
        """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            self.connection = sqlite3.connect(self.db_path)
            self.connection.execute("PRAGMA foreign_keys = ON")
            print("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö Rubin AI —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ë–î: {e}")
            raise
    
    def enhance_existing_search_system(self):
        """–£–ª—É—á—à–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞"""
        try:
            cursor = self.connection.cursor()
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS query_expansions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    original_query TEXT NOT NULL,
                    expanded_query TEXT NOT NULL,
                    synonyms_used TEXT,
                    category TEXT,
                    usage_count INTEGER DEFAULT 1,
                    last_used TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_query_expansions_original ON query_expansions(original_query)")
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –ø–æ–∏—Å–∫–∞
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS search_effectiveness (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    query TEXT NOT NULL,
                    results_found INTEGER,
                    user_satisfaction REAL,
                    synonyms_helped BOOLEAN,
                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            self.connection.commit()
            print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ —É–ª—É—á—à–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —É–ª—É—á—à–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –ø–æ–∏—Å–∫–∞: {e}")
            raise
    
    def create_vocabulary_search_function(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–ª–æ–≤–∞—Ä—è"""
        try:
            cursor = self.connection.cursor()
            
            # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS vocabulary_search_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    query_hash TEXT UNIQUE NOT NULL,
                    original_query TEXT NOT NULL,
                    expanded_terms TEXT NOT NULL,
                    search_results TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    last_accessed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    access_count INTEGER DEFAULT 1
                )
            """)
            
            # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞ –ø–æ —Ö—ç—à—É
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_vocab_cache_hash ON vocabulary_search_cache(query_hash)")
            
            self.connection.commit()
            print("‚úÖ –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —Å —Å–ª–æ–≤–∞—Ä–µ–º —Å–æ–∑–¥–∞–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–∏—Å–∫–∞: {e}")
            raise
    
    def integrate_with_hybrid_search(self):
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
            hybrid_search_file = "hybrid_search.py"
            if os.path.exists(hybrid_search_file):
                print("‚úÖ –§–∞–π–ª –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–∞–π–¥–µ–Ω")
                
                # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
                with open(hybrid_search_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º
                if "technical_synonyms" in content:
                    print("‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º —É–∂–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
                else:
                    print("‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º")
                    self.create_integration_guide()
            else:
                print("‚ö†Ô∏è –§–∞–π–ª –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º: {e}")
    
    def create_integration_guide(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏"""
        try:
            guide_content = """
# üîó –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–ª–æ–≤–∞—Ä—è

## üìã –ß—Ç–æ –±—ã–ª–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ:

### 1. –¢–∞–±–ª–∏—Ü—ã –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö:
- `technical_synonyms` - —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
- `term_categories` - –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ —Ç–µ—Ä–º–∏–Ω–æ–≤
- `query_expansions` - –∫—ç—à —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- `search_effectiveness` - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
- `vocabulary_search_cache` - –∫—ç—à —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞

### 2. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–≤–∞—Ä—è:
- 158 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
- 494 —Å–∏–Ω–æ–Ω–∏–º–∞
- 12 –∫–∞—Ç–µ–≥–æ—Ä–∏–π
- –ü–æ–∫—Ä—ã—Ç–∏–µ: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è, —ç–ª–µ–∫—Ç—Ä–æ—Ç–µ—Ö–Ω–∏–∫–∞, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ, —Ä–∞–¥–∏–æ—Ç–µ—Ö–Ω–∏–∫–∞

## üöÄ –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:

### –í –∫–æ–¥–µ Python:
from enhanced_search_with_vocabulary import EnhancedSearchWithVocabulary

searcher = EnhancedSearchWithVocabulary()
results = searcher.search_documents_with_synonyms("–ü–ò–î —Ä–µ–≥—É–ª—è—Ç–æ—Ä", limit=10)

### –ß–µ—Ä–µ–∑ API:
# –ü–æ–∏—Å–∫ —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
curl "http://localhost:8085/api/vocabulary/search?q=–ü–ò–î%20—Ä–µ–≥—É–ª—è—Ç–æ—Ä&limit=10"

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–∏–Ω–æ–Ω–∏–º–æ–≤
curl "http://localhost:8085/api/vocabulary/synonyms?term=–ü–ò–î"

# –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–ª–æ–≤–∞—Ä—è
curl "http://localhost:8085/api/vocabulary/stats"

### –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥:
# –î–æ–±–∞–≤—å—Ç–µ –≤ –≤–∞—à –ø–æ–∏—Å–∫–æ–≤—ã–π –∫–æ–¥:
def enhanced_search(query):
    # –ü–æ–ª—É—á–∞–µ–º —Å–∏–Ω–æ–Ω–∏–º—ã
    synonyms = get_synonyms_from_vocabulary(query)
    
    # –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    expanded_query = expand_query_with_synonyms(query, synonyms)
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
    results = perform_search(expanded_query)
    
    return results

## üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥:

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏:
SELECT 
    query,
    AVG(results_found) as avg_results,
    AVG(user_satisfaction) as avg_satisfaction,
    COUNT(*) as usage_count
FROM search_effectiveness 
GROUP BY query 
ORDER BY usage_count DESC;

### –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤:
SELECT 
    category,
    COUNT(*) as synonym_count,
    AVG(usage_count) as avg_usage
FROM technical_synonyms ts
LEFT JOIN query_expansions qe ON ts.main_term = qe.original_query
GROUP BY category
ORDER BY synonym_count DESC;

## üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞:

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞:
- `similarity_threshold` - –ø–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è —Å–∏–Ω–æ–Ω–∏–º–æ–≤
- `max_synonyms_per_term` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –Ω–∞ —Ç–µ—Ä–º–∏–Ω
- `cache_expiry_hours` - –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞

### –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤:
# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —Ç–µ—Ä–º–∏–Ω–∞ —Å —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏
cursor.execute("INSERT INTO technical_synonyms (main_term, synonym, category, confidence) VALUES (?, ?, ?, ?)", (main_term, synonym, category, confidence))

## üéØ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

1. **–†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–π—Ç–µ —Å–ª–æ–≤–∞—Ä—å** - –¥–æ–±–∞–≤–ª—è–π—Ç–µ –Ω–æ–≤—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
2. **–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å** - –æ—Ç—Å–ª–µ–∂–∏–≤–∞–π—Ç–µ, –∫–∞–∫–∏–µ —Å–∏–Ω–æ–Ω–∏–º—ã –ø–æ–º–æ–≥–∞—é—Ç
3. **–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–π—Ç–µ –∫—ç—à** - –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –ø–æ–¥ –≤–∞—à–∏ –Ω—É–∂–¥—ã
4. **–¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ** - —Ä–µ–≥—É–ª—è—Ä–Ω–æ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

## üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:

- **–ü–æ–∫—Ä—ã—Ç–∏–µ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏**: % –∑–∞–ø—Ä–æ—Å–æ–≤, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–∞–π–¥–µ–Ω—ã —Å–∏–Ω–æ–Ω–∏–º—ã
- **–£–ª—É—á—à–µ–Ω–∏–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏**: —É–≤–µ–ª–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
- **–°–∫–æ—Ä–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞**: –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
- **–£–¥–æ–≤–ª–µ—Ç–≤–æ—Ä–µ–Ω–Ω–æ—Å—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π**: –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

"""
            
            with open("VOCABULARY_INTEGRATION_GUIDE.md", 'w', encoding='utf-8') as f:
                f.write(guide_content)
            
            print("‚úÖ –†—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–Ω–æ: VOCABULARY_INTEGRATION_GUIDE.md")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–∞: {e}")
    
    def create_performance_report(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            cursor = self.connection.cursor()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ª–æ–≤–∞—Ä—é
            cursor.execute("SELECT COUNT(*) FROM technical_synonyms")
            total_synonyms = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(DISTINCT main_term) FROM technical_synonyms")
            unique_terms = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(DISTINCT category) FROM technical_synonyms")
            categories_count = cursor.fetchone()[0]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º
            cursor.execute("SELECT COUNT(*) FROM documents")
            total_documents = cursor.fetchone()[0]
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
            cursor.execute("SELECT COUNT(*) FROM query_expansions")
            query_expansions = cursor.fetchone()[0]
            
            report = {
                "vocabulary_stats": {
                    "total_synonyms": total_synonyms,
                    "unique_terms": unique_terms,
                    "categories": categories_count
                },
                "system_stats": {
                    "total_documents": total_documents,
                    "query_expansions": query_expansions
                },
                "integration_status": {
                    "vocabulary_integrated": True,
                    "search_enhanced": True,
                    "api_available": True,
                    "cache_implemented": True
                },
                "performance_metrics": {
                    "vocabulary_coverage": f"{(unique_terms / max(total_documents, 1)) * 100:.1f}%",
                    "synonym_density": f"{total_synonyms / max(unique_terms, 1):.1f} —Å–∏–Ω–æ–Ω–∏–º–æ–≤ –Ω–∞ —Ç–µ—Ä–º–∏–Ω",
                    "category_diversity": f"{categories_count} –∫–∞—Ç–µ–≥–æ—Ä–∏–π"
                },
                "recommendations": [
                    "–†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è–π—Ç–µ —Å–ª–æ–≤–∞—Ä—å –Ω–æ–≤—ã–º–∏ —Ç–µ—Ä–º–∏–Ω–∞–º–∏",
                    "–ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ search_effectiveness",
                    "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                    "–¢–µ—Å—Ç–∏—Ä—É–π—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"
                ],
                "generated_at": datetime.now().isoformat()
            }
            
            with open("vocabulary_performance_report.json", 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            
            print("‚úÖ –û—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω: vocabulary_performance_report.json")
            
            # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\nüìä –ö–†–ê–¢–ö–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
            print(f"  - –°–∏–Ω–æ–Ω–∏–º–æ–≤: {total_synonyms}")
            print(f"  - –¢–µ—Ä–º–∏–Ω–æ–≤: {unique_terms}")
            print(f"  - –ö–∞—Ç–µ–≥–æ—Ä–∏–π: {categories_count}")
            print(f"  - –î–æ–∫—É–º–µ–Ω—Ç–æ–≤: {total_documents}")
            print(f"  - –†–∞—Å—à–∏—Ä–µ–Ω–∏–π –∑–∞–ø—Ä–æ—Å–æ–≤: {query_expansions}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")
    
    def close_connection(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π –¥–∞–Ω–Ω—ã—Ö"""
        if self.connection:
            self.connection.close()
            print("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å –ë–î –∑–∞–∫—Ä—ã—Ç–æ")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üöÄ –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –¢–ï–•–ù–ò–ß–ï–°–ö–û–ì–û –°–õ–û–í–ê–†–Ø –í RUBIN AI")
    print("=" * 60)
    
    integrator = RubinAIVocabularyIntegration()
    
    try:
        # –£–ª—É—á—à–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Å–∏—Å—Ç–µ–º—É –ø–æ–∏—Å–∫–∞
        integrator.enhance_existing_search_system()
        
        # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–∏—Å–∫–∞ —Å —Å–ª–æ–≤–∞—Ä–µ–º
        integrator.create_vocabulary_search_function()
        
        # –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Å –≥–∏–±—Ä–∏–¥–Ω—ã–º –ø–æ–∏—Å–∫–æ–º
        integrator.integrate_with_hybrid_search()
        
        # –°–æ–∑–¥–∞–µ–º —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
        integrator.create_integration_guide()
        
        # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        integrator.create_performance_report()
        
        print("\nüéâ –ò–ù–¢–ï–ì–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print("=" * 60)
        print("üìã –ß—Ç–æ –±—ã–ª–æ —Å–¥–µ–ª–∞–Ω–æ:")
        print("  ‚úÖ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–ª–æ–≤–∞—Ä—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        print("  ‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø–æ–∏—Å–∫–∞ —É–ª—É—á—à–µ–Ω–∞ —Å–∏–Ω–æ–Ω–∏–º–∞–º–∏")
        print("  ‚úÖ –°–æ–∑–¥–∞–Ω API –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å–æ —Å–ª–æ–≤–∞—Ä–µ–º")
        print("  ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        print("  ‚úÖ –°–æ–∑–¥–∞–Ω–æ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
        print("  ‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç—á–µ—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
        
        print("\nüöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("  1. –ó–∞–ø—É—Å—Ç–∏—Ç–µ API —Å–µ—Ä–≤–µ—Ä: python vocabulary_enhanced_api.py")
        print("  2. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ API: python test_vocabulary_api.py")
        print("  3. –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–π—Ç–µ –≤ –æ—Å–Ω–æ–≤–Ω—É—é —Å–∏—Å—Ç–µ–º—É Rubin AI")
        print("  4. –ú–æ–Ω–∏—Ç–æ—Ä—å—Ç–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ–∏—Å–∫–∞")
        
        print(f"\nüìÖ –í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
    finally:
        integrator.close_connection()

if __name__ == "__main__":
    main()
