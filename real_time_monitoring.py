#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üì° –°–ò–°–¢–ï–ú–ê –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò
========================================================
–ü–æ—Å—Ç–æ—è–Ω–Ω–æ —Å–∫–∞–Ω–∏—Ä—É–µ–º –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Rubin AI
"""

import requests
import json
import time
import threading
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
import queue

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RealTimeInteractionMonitor:
    """–ú–æ–Ω–∏—Ç–æ—Ä –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
    
    def __init__(self):
        self.interaction_queue = queue.Queue()
        self.learning_patterns = {
            "error_diagnosis": [],
            "error_fixing": [],
            "modernization": [],
            "learning_process": [],
            "communication_style": []
        }
        self.rubin_knowledge_base = {}
        self.monitoring_active = False
        self.smart_dispatcher_url = "http://localhost:8080/api/chat"
        
    def start_monitoring(self):
        """–ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏"""
        print("üì° –ó–ê–ü–£–°–ö –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò")
        print("=" * 60)
        
        self.monitoring_active = True
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
        monitor_thread = threading.Thread(target=self._monitor_interactions)
        analyzer_thread = threading.Thread(target=self._analyze_patterns)
        teacher_thread = threading.Thread(target=self._teach_rubin_continuously)
        
        monitor_thread.daemon = True
        analyzer_thread.daemon = True
        teacher_thread.daemon = True
        
        monitor_thread.start()
        analyzer_thread.start()
        teacher_thread.start()
        
        print("‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω")
        print("üìä –ê–Ω–∞–ª–∏–∑ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –∞–∫—Ç–∏–≤–µ–Ω")
        print("üß† –ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ Rubin AI –∞–∫—Ç–∏–≤–Ω–æ")
        
        return monitor_thread, analyzer_thread, teacher_thread
    
    def _monitor_interactions(self):
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        while self.monitoring_active:
            try:
                # –°–∏–º—É–ª–∏—Ä—É–µ–º –ø–æ–ª—É—á–µ–Ω–∏–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
                # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ª–æ–≥–æ–≤
                interaction = self._simulate_interaction()
                if interaction:
                    self.interaction_queue.put(interaction)
                
                time.sleep(5)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
                time.sleep(10)
    
    def _simulate_interaction(self) -> Optional[Dict[str, Any]]:
        """–°–∏–º—É–ª–∏—Ä—É–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
        # –í —Ä–µ–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ –∑–¥–µ—Å—å –±—ã–ª –±—ã API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π
        interactions = [
            {
                "user_message": "HTTP 500 –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ PLC —Ñ–∞–π–ª–∞",
                "assistant_response": "–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø—Ä–æ–±–ª–µ–º—É: —Å–µ—Ä–≤–µ—Ä controllers –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–∏–º–µ–Ω—è—é fallback –º–µ—Ö–∞–Ω–∏–∑–º",
                "context": {"error_type": "HTTP_500", "file_type": "PLC"}
            },
            {
                "user_message": "–ö–∞–∫ –º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É VMB630?",
                "assistant_response": "–ü—Ä–µ–¥–ª–∞–≥–∞—é –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞—Ç—Ç–µ—Ä–Ω—ã Singleton, Observer, Factory –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã",
                "context": {"topic": "modernization", "system": "VMB630"}
            },
            {
                "user_message": "–û–±—É—á–∏ Rubin AI –ø–æ–Ω–∏–º–∞–Ω–∏—é –æ—à–∏–±–æ–∫",
                "assistant_response": "–°–æ–∑–¥–∞—é —Å–∏—Å—Ç–µ–º—É –æ–±—É—á–µ–Ω–∏—è —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ—à–∏–±–æ–∫",
                "context": {"learning_type": "error_handling", "target": "Rubin_AI"}
            }
        ]
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω–æ–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ
        import random
        if random.random() < 0.3:  # 30% –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
            return random.choice(interactions)
        return None
    
    def _analyze_patterns(self):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π"""
        while self.monitoring_active:
            try:
                if not self.interaction_queue.empty():
                    interaction = self.interaction_queue.get()
                    self._process_interaction(interaction)
                
                time.sleep(2)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {e}")
                time.sleep(5)
    
    def _process_interaction(self, interaction: Dict[str, Any]):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ"""
        user_msg = interaction["user_message"]
        assistant_msg = interaction["assistant_response"]
        context = interaction["context"]
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = self._extract_patterns(user_msg, assistant_msg, context)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        self._update_knowledge_base(patterns, context)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ: {patterns}")
    
    def _extract_patterns(self, user_msg: str, assistant_msg: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è"""
        patterns = {
            "timestamp": datetime.now().isoformat(),
            "error_diagnosis": self._detect_error_diagnosis(user_msg, assistant_msg),
            "error_fixing": self._detect_error_fixing(user_msg, assistant_msg),
            "modernization": self._detect_modernization(user_msg, assistant_msg),
            "learning_process": self._detect_learning_process(user_msg, assistant_msg),
            "communication_style": self._analyze_communication_style(user_msg, assistant_msg),
            "context": context
        }
        
        return patterns
    
    def _detect_error_diagnosis(self, user_msg: str, assistant_msg: str) -> Dict[str, Any]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É –æ—à–∏–±–æ–∫"""
        error_keywords = ["–æ—à–∏–±–∫–∞", "error", "–ø—Ä–æ–±–ª–µ–º–∞", "–Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç", "HTTP 500"]
        diagnosis_keywords = ["–∞–Ω–∞–ª–∏–∑", "–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞", "–ø—Ä–æ–≤–µ—Ä–∫–∞", "–ø—Ä–∏—á–∏–Ω–∞"]
        
        has_error = any(keyword in user_msg.lower() for keyword in error_keywords)
        has_diagnosis = any(keyword in assistant_msg.lower() for keyword in diagnosis_keywords)
        
        if has_error and has_diagnosis:
            return {
                "detected": True,
                "error_type": self._classify_error(user_msg),
                "diagnosis_method": self._extract_diagnosis_method(assistant_msg),
                "confidence": 0.8
            }
        
        return {"detected": False}
    
    def _detect_error_fixing(self, user_msg: str, assistant_msg: str) -> Dict[str, Any]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫"""
        fixing_keywords = ["–∏—Å–ø—Ä–∞–≤–∏—Ç—å", "fix", "—Ä–µ—à–∏—Ç—å", "—É—Å—Ç—Ä–∞–Ω–∏—Ç—å", "fallback"]
        solution_keywords = ["—Ä–µ—à–µ–Ω–∏–µ", "solution", "–º–µ—Ö–∞–Ω–∏–∑–º", "–æ–±—Ö–æ–¥"]
        
        has_fixing = any(keyword in user_msg.lower() for keyword in fixing_keywords)
        has_solution = any(keyword in assistant_msg.lower() for keyword in solution_keywords)
        
        if has_fixing and has_solution:
            return {
                "detected": True,
                "fix_type": self._classify_fix(user_msg),
                "solution_approach": self._extract_solution_approach(assistant_msg),
                "confidence": 0.7
            }
        
        return {"detected": False}
    
    def _detect_modernization(self, user_msg: str, assistant_msg: str) -> Dict[str, Any]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—é"""
        modern_keywords = ["–º–æ–¥–µ—Ä–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å", "—É–ª—É—á—à–∏—Ç—å", "–æ–±–Ω–æ–≤–∏—Ç—å", "–ø–∞—Ç—Ç–µ—Ä–Ω", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞"]
        pattern_keywords = ["singleton", "observer", "factory", "strategy", "command"]
        
        has_modern = any(keyword in user_msg.lower() for keyword in modern_keywords)
        has_patterns = any(keyword in assistant_msg.lower() for keyword in pattern_keywords)
        
        if has_modern and has_patterns:
            return {
                "detected": True,
                "modernization_type": self._classify_modernization(user_msg),
                "patterns_used": self._extract_patterns_used(assistant_msg),
                "confidence": 0.9
            }
        
        return {"detected": False}
    
    def _detect_learning_process(self, user_msg: str, assistant_msg: str) -> Dict[str, Any]:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è"""
        learning_keywords = ["–æ–±—É—á–∏—Ç—å", "–Ω–∞—É—á–∏—Ç—å", "–æ–±—É—á–µ–Ω–∏–µ", "–ø–æ–Ω–∏–º–∞–Ω–∏–µ", "—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ"]
        teaching_keywords = ["—É—Ä–æ–∫", "–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è", "–ø—Ä–∏–º–µ—Ä", "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ"]
        
        has_learning = any(keyword in user_msg.lower() for keyword in learning_keywords)
        has_teaching = any(keyword in assistant_msg.lower() for keyword in teaching_keywords)
        
        if has_learning and has_teaching:
            return {
                "detected": True,
                "learning_type": self._classify_learning(user_msg),
                "teaching_method": self._extract_teaching_method(assistant_msg),
                "confidence": 0.8
            }
        
        return {"detected": False}
    
    def _analyze_communication_style(self, user_msg: str, assistant_msg: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è"""
        return {
            "user_tone": self._analyze_tone(user_msg),
            "assistant_tone": self._analyze_tone(assistant_msg),
            "technical_level": self._analyze_technical_level(user_msg, assistant_msg),
            "formality": self._analyze_formality(user_msg, assistant_msg)
        }
    
    def _classify_error(self, message: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –æ—à–∏–±–∫—É"""
        if "HTTP 500" in message:
            return "HTTP_500"
        elif "plc" in message.lower():
            return "PLC_ERROR"
        elif "—Å–µ—Ä–≤–µ—Ä" in message.lower():
            return "SERVER_ERROR"
        else:
            return "GENERAL_ERROR"
    
    def _classify_fix(self, message: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ"""
        if "fallback" in message.lower():
            return "FALLBACK_MECHANISM"
        elif "–æ–±–Ω–æ–≤–∏—Ç—å" in message.lower():
            return "UPDATE"
        else:
            return "GENERAL_FIX"
    
    def _classify_modernization(self, message: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –º–æ–¥–µ—Ä–Ω–∏–∑–∞—Ü–∏—é"""
        if "–ø–∞—Ç—Ç–µ—Ä–Ω" in message.lower():
            return "DESIGN_PATTERNS"
        elif "–∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞" in message.lower():
            return "ARCHITECTURE"
        else:
            return "GENERAL_MODERNIZATION"
    
    def _classify_learning(self, message: str) -> str:
        """–ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º –æ–±—É—á–µ–Ω–∏–µ"""
        if "–ø–æ—Å—Ç–æ—è–Ω–Ω–æ" in message.lower():
            return "CONTINUOUS_LEARNING"
        elif "–æ—à–∏–±–∫–∏" in message.lower():
            return "ERROR_HANDLING_LEARNING"
        else:
            return "GENERAL_LEARNING"
    
    def _extract_diagnosis_method(self, response: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–æ–¥—ã –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏"""
        methods = []
        if "–∞–Ω–∞–ª–∏–∑" in response.lower():
            methods.append("ANALYSIS")
        if "–ø—Ä–æ–≤–µ—Ä–∫–∞" in response.lower():
            methods.append("CHECKING")
        if "—Å—Ç–∞—Ç—É—Å" in response.lower():
            methods.append("STATUS_CHECK")
        return methods
    
    def _extract_solution_approach(self, response: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ–¥—Ö–æ–¥ –∫ —Ä–µ—à–µ–Ω–∏—é"""
        if "fallback" in response.lower():
            return "FALLBACK_APPROACH"
        elif "–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ" in response.lower():
            return "UPDATE_APPROACH"
        else:
            return "GENERAL_APPROACH"
    
    def _extract_patterns_used(self, response: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã"""
        patterns = []
        if "singleton" in response.lower():
            patterns.append("SINGLETON")
        if "observer" in response.lower():
            patterns.append("OBSERVER")
        if "factory" in response.lower():
            patterns.append("FACTORY")
        return patterns
    
    def _extract_teaching_method(self, response: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–æ–¥—ã –æ–±—É—á–µ–Ω–∏—è"""
        methods = []
        if "–¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è" in response.lower():
            methods.append("DEMONSTRATION")
        if "–ø—Ä–∏–º–µ—Ä" in response.lower():
            methods.append("EXAMPLE")
        if "–æ–±—ä—è—Å–Ω–µ–Ω–∏–µ" in response.lower():
            methods.append("EXPLANATION")
        return methods
    
    def _analyze_tone(self, text: str) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–æ–Ω"""
        if "!" in text or "üéâ" in text:
            return "POSITIVE"
        elif "‚ùå" in text or "–æ—à–∏–±–∫–∞" in text.lower():
            return "NEGATIVE"
        else:
            return "NEUTRAL"
    
    def _analyze_technical_level(self, user_msg: str, assistant_msg: str) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å"""
        tech_terms = ["API", "HTTP", "—Å–µ—Ä–≤–µ—Ä", "–∫–æ–¥", "–∞–ª–≥–æ—Ä–∏—Ç–º"]
        total_tech = sum(1 for term in tech_terms if term.lower() in (user_msg + assistant_msg).lower())
        
        if total_tech > 3:
            return "HIGH"
        elif total_tech > 1:
            return "MEDIUM"
        else:
            return "LOW"
    
    def _analyze_formality(self, user_msg: str, assistant_msg: str) -> str:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç—å"""
        if "—Ç—ã" in user_msg.lower() and "–º—ã" in assistant_msg.lower():
            return "INFORMAL"
        else:
            return "FORMAL"
    
    def _update_knowledge_base(self, patterns: Dict[str, Any], context: Dict[str, Any]):
        """–û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π Rubin AI"""
        for pattern_type, pattern_data in patterns.items():
            if isinstance(pattern_data, dict) and pattern_data.get("detected"):
                if pattern_type not in self.rubin_knowledge_base:
                    self.rubin_knowledge_base[pattern_type] = []
                
                knowledge_entry = {
                    "timestamp": datetime.now().isoformat(),
                    "pattern": pattern_data,
                    "context": context,
                    "confidence": pattern_data.get("confidence", 0.5)
                }
                
                self.rubin_knowledge_base[pattern_type].append(knowledge_entry)
                
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π
                if len(self.rubin_knowledge_base[pattern_type]) > 100:
                    self.rubin_knowledge_base[pattern_type] = self.rubin_knowledge_base[pattern_type][-100:]
    
    def _teach_rubin_continuously(self):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ –æ–±—É—á–∞–µ–º Rubin AI"""
        while self.monitoring_active:
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                if self._has_new_knowledge():
                    self._teach_rubin_new_patterns()
                
                time.sleep(30)  # –û–±—É—á–∞–µ–º –∫–∞–∂–¥—ã–µ 30 —Å–µ–∫—É–Ω–¥
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: {e}")
                time.sleep(60)
    
    def _has_new_knowledge(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è"""
        total_patterns = sum(len(patterns) for patterns in self.rubin_knowledge_base.values())
        return total_patterns > 0
    
    def _teach_rubin_new_patterns(self):
        """–û–±—É—á–∞–µ–º Rubin AI –Ω–æ–≤—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"""
        try:
            # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            learning_message = self._create_learning_message()
            
            if learning_message:
                response = requests.post(self.smart_dispatcher_url, 
                                      json={'message': learning_message})
                
                if response.status_code == 200:
                    logger.info("Rubin AI –æ–±—É—á–µ–Ω –Ω–æ–≤—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º")
                else:
                    logger.warning(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Rubin AI: {response.status_code}")
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è Rubin AI: {e}")
    
    def _create_learning_message(self) -> Optional[str]:
        """–°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if not self.rubin_knowledge_base:
            return None
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        recent_patterns = []
        for pattern_type, patterns in self.rubin_knowledge_base.items():
            if patterns:
                recent_patterns.append({
                    "type": pattern_type,
                    "count": len(patterns),
                    "latest": patterns[-1]
                })
        
        if recent_patterns:
            message = "–ü—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ: Rubin, —è –Ω–∞–±–ª—é–¥–∞—é –Ω–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ –Ω–∞—à–µ–º –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–∏: "
            for pattern in recent_patterns:
                message += f"{pattern['type']} ({pattern['count']} —Å–ª—É—á–∞–µ–≤), "
            
            message += "–ö–∞–∫ —Ç—ã –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–≤–æ–µ–π —Ä–∞–±–æ—Ç—ã?"
            return message
        
        return None
    
    def stop_monitoring(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥"""
        self.monitoring_active = False
        print("üõë –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    def get_learning_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–∞–µ–º –æ—Ç—á–µ—Ç –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        return {
            "timestamp": datetime.now().isoformat(),
            "knowledge_base": self.rubin_knowledge_base,
            "total_patterns": sum(len(patterns) for patterns in self.rubin_knowledge_base.values()),
            "pattern_types": list(self.rubin_knowledge_base.keys())
        }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    print("üì° –°–ò–°–¢–ï–ú–ê –ú–û–ù–ò–¢–û–†–ò–ù–ì–ê –í–ó–ê–ò–ú–û–î–ï–ô–°–¢–í–ò–Ø –í –†–ï–ê–õ–¨–ù–û–ú –í–†–ï–ú–ï–ù–ò")
    print("=" * 70)
    print("–¶–µ–ª—å: –ü–æ—Å—Ç–æ—è–Ω–Ω–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å Rubin AI")
    print("=" * 70)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä
    monitor = RealTimeInteractionMonitor()
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
        threads = monitor.start_monitoring()
        
        print("\nüîÑ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–∫—Ç–∏–≤–µ–Ω...")
        print("–ù–∞–∂–º–∏—Ç–µ Ctrl+C –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        
        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        for thread in threads:
            thread.join()
            
    except KeyboardInterrupt:
        print("\nüõë –ü–æ–ª—É—á–µ–Ω —Å–∏–≥–Ω–∞–ª –æ—Å—Ç–∞–Ω–æ–≤–∫–∏")
        monitor.stop_monitoring()
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        report = monitor.get_learning_report()
        print(f"\nüìä –§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢:")
        print(f"üìà –í—Å–µ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {report['total_patterns']}")
        print(f"üîç –¢–∏–ø—ã –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {report['pattern_types']}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        try:
            with open('REAL_TIME_MONITORING_REPORT.json', 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print("üìÑ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: REAL_TIME_MONITORING_REPORT.json")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç—á–µ—Ç–∞: {e}")

if __name__ == "__main__":
    main()










