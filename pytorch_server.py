#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üî• PYTORCH SERVER FOR RUBIN AI
==============================
–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å PyTorch –≤ Rubin AI
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import logging
import json
from datetime import datetime
from typing import Dict, List, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

class PyTorchExpert:
    """–≠–∫—Å–ø–µ—Ä—Ç –ø–æ PyTorch –¥–ª—è Rubin AI"""
    
    def __init__(self):
        self.knowledge_base = {
            "device_management": {
                "description": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏ (CPU/GPU)",
                "best_practices": [
                    "–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA",
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å torch.device() –¥–ª—è —è–≤–Ω–æ–≥–æ —É–∫–∞–∑–∞–Ω–∏—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞",
                    "–ü–µ—Ä–µ–Ω–æ—Å–∏—Ç—å –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ"
                ],
                "common_errors": [
                    "RuntimeError: Expected all tensors to be on the same device",
                    "–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –º–µ–∂–¥—É –º–æ–¥–µ–ª—å—é –∏ –¥–∞–Ω–Ω—ã–º–∏"
                ],
                "solutions": [
                    "model = model.to(device)",
                    "data = data.to(device)",
                    "target = target.to(device)"
                ]
            },
            
            "model_saving": {
                "description": "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π",
                "best_practices": [
                    "–°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ state_dict, –Ω–µ –≤—Å—é –º–æ–¥–µ–ª—å",
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .eval() –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π",
                    "–°–æ—Ö—Ä–∞–Ω—è—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–º–µ—Å—Ç–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"
                ],
                "common_errors": [
                    "Missing key(s) in state_dict",
                    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π"
                ],
                "solutions": [
                    "torch.save(model.state_dict(), 'model.pth')",
                    "model.load_state_dict(torch.load('model.pth'))",
                    "model.eval()"
                ]
            },
            
            "gradient_management": {
                "description": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏",
                "best_practices": [
                    "–í—Å–µ–≥–¥–∞ –æ–±–Ω—É–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–µ—Ä–µ–¥ backward()",
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å optimizer.zero_grad()",
                    "–ù–µ –∑–∞–±—ã–≤–∞—Ç—å –ø—Ä–æ optimizer.step()"
                ],
                "common_errors": [
                    "–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏",
                    "–ó–∞–±—ã–ª–∏ –æ–±–Ω—É–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã"
                ],
                "solutions": [
                    "optimizer.zero_grad()",
                    "loss.backward()",
                    "optimizer.step()"
                ]
            },
            
            "model_modes": {
                "description": "–†–µ–∂–∏–º—ã –º–æ–¥–µ–ª–∏ (train/eval)",
                "best_practices": [
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å model.train() –¥–ª—è –æ–±—É—á–µ–Ω–∏—è",
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å model.eval() –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å torch.no_grad() –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"
                ],
                "common_errors": [
                    "–ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ Dropout",
                    "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ä–∞–±–æ—Ç–∞ BatchNorm"
                ],
                "solutions": [
                    "model.train() - –≤–∫–ª—é—á–∞–µ—Ç Dropout, BatchNorm",
                    "model.eval() - –æ—Ç–∫–ª—é—á–∞–µ—Ç Dropout, —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç BatchNorm",
                    "torch.no_grad() - –æ—Ç–∫–ª—é—á–∞–µ—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤"
                ]
            },
            
            "tensor_debugging": {
                "description": "–û—Ç–ª–∞–¥–∫–∞ —Ç–µ–Ω–∑–æ—Ä–æ–≤",
                "best_practices": [
                    "–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ñ–æ—Ä–º—ã —Ç–µ–Ω–∑–æ—Ä–æ–≤",
                    "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å print() –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏",
                    "–ü—Ä–æ–≤–µ—Ä—è—Ç—å —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤"
                ],
                "common_errors": [
                    "RuntimeError: size mismatch",
                    "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"
                ],
                "solutions": [
                    "print(f'Shape: {tensor.shape}')",
                    "print(f'Dtype: {tensor.dtype}')",
                    "print(f'Device: {tensor.device}')"
                ]
            }
        }
        
        self.learning_paths = {
            "beginner": [
                "–û—Å–Ω–æ–≤—ã PyTorch",
                "–†–∞–±–æ—Ç–∞ —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏",
                "–ü—Ä–æ—Å—Ç–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å",
                "–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
            ],
            "intermediate": [
                "CNN –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π",
                "RNN –¥–ª—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π",
                "–¢—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
                "–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è"
            ],
            "advanced": [
                "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã",
                "GAN (Generative Adversarial Networks)",
                "Reinforcement Learning",
                "Custom Layers"
            ]
        }
    
    def analyze_pytorch_question(self, question: str) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ –≤–æ–ø—Ä–æ—Å–∞ –æ PyTorch"""
        
        question_lower = question.lower()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –≤–æ–ø—Ä–æ—Å–∞
        if any(word in question_lower for word in ['—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ', 'device', 'gpu', 'cuda', 'cpu']):
            category = "device_management"
        elif any(word in question_lower for word in ['—Å–æ—Ö—Ä–∞–Ω', '–∑–∞–≥—Ä—É–∑', 'save', 'load', 'model']):
            category = "model_saving"
        elif any(word in question_lower for word in ['–≥—Ä–∞–¥–∏–µ–Ω—Ç', 'gradient', 'backward', 'optimizer']):
            category = "gradient_management"
        elif any(word in question_lower for word in ['—Ä–µ–∂–∏–º', 'mode', 'train', 'eval', 'test']):
            category = "model_modes"
        elif any(word in question_lower for word in ['—Ñ–æ—Ä–º–∞', 'shape', '—Ä–∞–∑–º–µ—Ä', 'size', '–æ—Ç–ª–∞–¥']):
            category = "tensor_debugging"
        else:
            category = "general"
        
        return {
            "category": category,
            "confidence": 0.9 if category != "general" else 0.6,
            "question_type": "pytorch_expert"
        }
    
    def generate_pytorch_response(self, question: str, analysis: Dict[str, Any]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –æ PyTorch"""
        
        category = analysis["category"]
        
        if category == "device_management":
            return self._generate_device_response(question)
        elif category == "model_saving":
            return self._generate_saving_response(question)
        elif category == "gradient_management":
            return self._generate_gradient_response(question)
        elif category == "model_modes":
            return self._generate_modes_response(question)
        elif category == "tensor_debugging":
            return self._generate_debugging_response(question)
        else:
            return self._generate_general_response(question)
    
    def _generate_device_response(self, question: str) -> str:
        """–û—Ç–≤–µ—Ç –æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞–º–∏"""
        return """üî• **PYTORCH: –£–ü–†–ê–í–õ–ï–ù–ò–ï –£–°–¢–†–û–ô–°–¢–í–ê–ú–ò**

**üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:**
1. **–ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA:** `torch.cuda.is_available()`
2. **–í—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞:** `device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')`
3. **–ü–µ—Ä–µ–Ω–æ—Å –º–æ–¥–µ–ª–∏:** `model = model.to(device)`
4. **–ü–µ—Ä–µ–Ω–æ—Å –¥–∞–Ω–Ω—ã—Ö:** `data = data.to(device)`

**üí° –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:**
- –í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å GPU –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
- –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —è–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞

**‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏:**
- `RuntimeError: Expected all tensors to be on the same device`
- –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –º–µ–∂–¥—É –º–æ–¥–µ–ª—å—é –∏ –¥–∞–Ω–Ω—ã–º–∏

**üîß –†–µ—à–µ–Ω–∏–µ:**
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
for data, target in train_loader:
    data = data.to(device)
    target = target.to(device)
    # ... –æ–±—É—á–µ–Ω–∏–µ
```

**üìä –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ GPU:**
- –î–æ 100x —É—Å–∫–æ—Ä–µ–Ω–∏–µ –¥–ª—è –º–∞—Ç—Ä–∏—á–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
- –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å —Ä–∞–±–æ—Ç—ã —Å –±–æ–ª—å—à–∏–º–∏ –±–∞—Ç—á–∞–º–∏
- –£—Å–∫–æ—Ä–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è —Å–ª–æ–∂–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
    
    def _generate_saving_response(self, question: str) -> str:
        """–û—Ç–≤–µ—Ç –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π"""
        return """üíæ **PYTORCH: –°–û–•–†–ê–ù–ï–ù–ò–ï –ò –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ï–ô**

**üéØ –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ–¥—Ö–æ–¥:**
1. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ:** `torch.save(model.state_dict(), 'model.pth')`
2. **–ó–∞–≥—Ä—É–∑–∫–∞:** `model.load_state_dict(torch.load('model.pth'))`
3. **–†–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏:** `model.eval()`

**üí° –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:**
- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (state_dict), –Ω–µ –≤—Å—é –º–æ–¥–µ–ª—å
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ .eval() –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤–º–µ—Å—Ç–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏

**‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏:**
- `Missing key(s) in state_dict`
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤—Å–µ–π –º–æ–¥–µ–ª–∏ (–Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

**üîß –ü–æ–ª–Ω—ã–π –ø—Ä–∏–º–µ—Ä:**
```python
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
torch.save(model.state_dict(), 'model.pth')

# –ó–∞–≥—Ä—É–∑–∫–∞
model = MNISTClassifier()  # –¢–æ—Ç –∂–µ –∫–ª–∞—Å—Å!
model.load_state_dict(torch.load('model.pth'))
model.eval()  # –í–∞–∂–Ω–æ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
with torch.no_grad():
    output = model(data)
    prediction = output.argmax().item()
```

**üìã –ß—Ç–æ —Ç–∞–∫–æ–µ state_dict?**
- –°–ª–æ–≤–∞—Ä—å —Å –æ–±—É—á–∞–µ–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–æ–¥–µ–ª–∏
- –°–æ–¥–µ—Ä–∂–∏—Ç –≤–µ—Å–∞ –∏ —Å–º–µ—â–µ–Ω–∏—è –≤—Å–µ—Ö —Å–ª–æ–µ–≤
- –ù–µ –≤–∫–ª—é—á–∞–µ—Ç –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏"""
    
    def _generate_gradient_response(self, question: str) -> str:
        """–û—Ç–≤–µ—Ç –æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏"""
        return """‚ö° **PYTORCH: –£–ü–†–ê–í–õ–ï–ù–ò–ï –ì–†–ê–î–ò–ï–ù–¢–ê–ú–ò**

**üéØ –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å:**
1. **–û–±–Ω—É–ª–µ–Ω–∏–µ:** `optimizer.zero_grad()`
2. **–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥:** `output = model(data)`
3. **–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å:** `loss = criterion(output, target)`
4. **–û–±—Ä–∞—Ç–Ω—ã–π –ø—Ä–æ—Ö–æ–¥:** `loss.backward()`
5. **–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ:** `optimizer.step()`

**üí° –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:**
- –í—Å–µ–≥–¥–∞ –æ–±–Ω—É–ª—è–π—Ç–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–µ—Ä–µ–¥ backward()
- –ù–µ –∑–∞–±—ã–≤–∞–π—Ç–µ –ø—Ä–æ optimizer.step()
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –æ–ø–µ—Ä–∞—Ü–∏–π

**‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –æ—à–∏–±–∫–∏:**
- –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏
- –ó–∞–±—ã–ª–∏ –æ–±–Ω—É–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –æ–ø–µ—Ä–∞—Ü–∏–π

**üîß –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è:**
```python
for data, target in train_loader:
    optimizer.zero_grad()  # –û–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
    output = model(data)
    loss = criterion(output, target)
    loss.backward()        # –í—ã—á–∏—Å–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
    optimizer.step()       # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
```

**‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ:**
```python
for data, target in train_loader:
    output = model(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()  # –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è!
```

**üìä –ü–æ—á–µ–º—É —ç—Ç–æ –≤–∞–∂–Ω–æ:**
- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
- –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- –ò–∑–±–µ–≥–∞–µ—Ç –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è"""
    
    def _generate_modes_response(self, question: str) -> str:
        """–û—Ç–≤–µ—Ç –æ —Ä–µ–∂–∏–º–∞—Ö –º–æ–¥–µ–ª–∏"""
        return """üîÑ **PYTORCH: –†–ï–ñ–ò–ú–´ –ú–û–î–ï–õ–ò (TRAIN/EVAL)**

**üéØ –î–≤–∞ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∂–∏–º–∞:**
1. **–û–±—É—á–µ–Ω–∏–µ:** `model.train()`
2. **–û—Ü–µ–Ω–∫–∞:** `model.eval()`

**üí° –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:**
- **model.train()** - –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
- **model.eval()** - –≤–æ –≤—Ä–µ–º—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è/–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- **torch.no_grad()** - –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π (—ç–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏)

**‚ö†Ô∏è –ß—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –≤ –∫–∞–∂–¥–æ–º —Ä–µ–∂–∏–º–µ:**
- **train():** –í–∫–ª—é—á–∞–µ—Ç Dropout, BatchNorm –æ–±—É—á–∞–µ—Ç—Å—è
- **eval():** –û—Ç–∫–ª—é—á–∞–µ—Ç Dropout, —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç BatchNorm

**üîß –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:**
```python
# –û–±—É—á–µ–Ω–∏–µ
model.train()
for data, target in train_loader:
    optimizer.zero_grad()
    output = model(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
model.eval()
with torch.no_grad():
    for data, target in test_loader:
        output = model(data)
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
```

**üìä –ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞:**
- –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ Dropout –∏ BatchNorm
- –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏ –ø—Ä–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö
- –°—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

**üéØ –í–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã:**
- –í—Å–µ–≥–¥–∞ –ø–µ—Ä–µ–∫–ª—é—á–∞–π—Ç–µ —Ä–µ–∂–∏–º —è–≤–Ω–æ
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ torch.no_grad() –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
- –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ—Ç–ª–∞–¥–∫–µ"""
    
    def _generate_debugging_response(self, question: str) -> str:
        """–û—Ç–≤–µ—Ç –æ –æ—Ç–ª–∞–¥–∫–µ —Ç–µ–Ω–∑–æ—Ä–æ–≤"""
        return """üêõ **PYTORCH: –û–¢–õ–ê–î–ö–ê –¢–ï–ù–ó–û–†–û–í**

**üéØ –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏:**
1. **–§–æ—Ä–º–∞:** `tensor.shape`
2. **–¢–∏–ø –¥–∞–Ω–Ω—ã—Ö:** `tensor.dtype`
3. **–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ:** `tensor.device`
4. **–ó–Ω–∞—á–µ–Ω–∏—è:** `tensor.min()`, `tensor.max()`

**üí° –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –æ—Ç–ª–∞–¥–∫–∏:**
```python
print(f"–§–æ—Ä–º–∞: {tensor.shape}")
print(f"–¢–∏–ø: {tensor.dtype}")
print(f"–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {tensor.device}")
print(f"–ú–∏–Ω–∏–º—É–º: {tensor.min()}")
print(f"–ú–∞–∫—Å–∏–º—É–º: {tensor.max()}")
print(f"–°—Ä–µ–¥–Ω–µ–µ: {tensor.mean()}")
```

**‚ö†Ô∏è –ß–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:**
- `RuntimeError: size mismatch`
- –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
- –ü—Ä–æ–±–ª–µ–º—ã —Å —Ç–∏–ø–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö

**üîß –û—Ç–ª–∞–¥–æ—á–Ω—ã–π —à–∞–±–ª–æ–Ω:**
```python
def debug_tensor(name, tensor):
    print(f"{name}:")
    print(f"  Shape: {tensor.shape}")
    print(f"  Dtype: {tensor.dtype}")
    print(f"  Device: {tensor.device}")
    print(f"  Min: {tensor.min()}")
    print(f"  Max: {tensor.max()}")
    print()

# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
debug_tensor("Input", data)
debug_tensor("Output", output)
debug_tensor("Target", target)
```

**üìä –ü–æ–ª–µ–∑–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏:**
- –°–æ–≤–ø–∞–¥–∞—é—Ç –ª–∏ —Ä–∞–∑–º–µ—Ä—ã –±–∞—Ç—á–∞?
- –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π –ª–∏ —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö?
- –ù–∞ –æ–¥–Ω–æ–º –ª–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ —Ç–µ–Ω–∑–æ—Ä—ã?
- –ù–æ—Ä–º–∞–ª—å–Ω—ã–µ –ª–∏ –∑–Ω–∞—á–µ–Ω–∏—è?

**üéØ –°–æ–≤–µ—Ç—ã:**
- –î–æ–±–∞–≤–ª—è–π—Ç–µ –æ—Ç–ª–∞–¥–æ—á–Ω—ã–µ –ø—Ä–∏–Ω—Ç—ã –≤ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö
- –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ñ–æ—Ä–º—ã —Ç–µ–Ω–∑–æ—Ä–æ–≤ –ø—Ä–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ assert –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —É—Å–ª–æ–≤–∏–π"""
    
    def _generate_general_response(self, question: str) -> str:
        """–û–±—â–∏–π –æ—Ç–≤–µ—Ç –æ PyTorch"""
        return """üî• **PYTORCH: –û–ë–©–ò–ï –ü–†–ò–ù–¶–ò–ü–´**

**üéØ –û—Å–Ω–æ–≤—ã PyTorch:**
- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –≥—Ä–∞—Ñ—ã –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
- –ò–Ω—Ç—É–∏—Ç–∏–≤–Ω—ã–π API
- –û—Ç–ª–∏—á–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

**üí° –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏:**
1. **–¢–µ–Ω–∑–æ—Ä—ã** - –æ—Å–Ω–æ–≤–∞ –≤—Å–µ—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
2. **–ê–≤—Ç–æ–¥–∏—Ñ—Ñ–µ—Ä–µ–Ω—Ü–∏–∞—Ü–∏—è** - –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
3. **–ú–æ–¥—É–ª–∏** - —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
4. **–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã** - –∞–ª–≥–æ—Ä–∏—Ç–º—ã –æ–±—É—á–µ–Ω–∏—è

**üìö –ü—É—Ç–∏ –∏–∑—É—á–µ–Ω–∏—è:**
- **–ù–∞—á–∏–Ω–∞—é—â–∏–π:** –û—Å–Ω–æ–≤—ã, –ø—Ä–æ—Å—Ç—ã–µ —Å–µ—Ç–∏
- **–°—Ä–µ–¥–Ω–∏–π:** CNN, RNN, —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
- **–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π:** –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã, GAN, RL

**üîß –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏:**
- –ù–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤
- –ü—Ä–æ–≤–µ—Ä—è–π—Ç–µ —Ñ–æ—Ä–º—ã —Ç–µ–Ω–∑–æ—Ä–æ–≤
- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ä–µ–∂–∏–º—ã –º–æ–¥–µ–ª–∏
- –°–æ—Ö—Ä–∞–Ω—è–π—Ç–µ —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏

**üìñ –ü–æ–ª–µ–∑–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã:**
- –û—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è PyTorch
- PyTorch Tutorials
- Papers With Code

**üéØ –ü–æ–º–Ω–∏—Ç–µ:** 80% —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏, 20% –º–∞–≥–∏–∏ –º–æ–¥–µ–ª–µ–π!"""

# –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —ç–∫—Å–ø–µ—Ä—Ç–∞
pytorch_expert = PyTorchExpert()

@app.route('/api/pytorch/chat', methods=['POST'])
def pytorch_chat():
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–∏–Ω—Ç –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ PyTorch"""
    try:
        data = request.get_json()
        question = data.get('message', '')
        
        if not question:
            return jsonify({
                'success': False,
                'error': '–í–æ–ø—Ä–æ—Å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'
            }), 400
        
        logger.info(f"üî• –ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å –æ PyTorch: {question[:50]}...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–æ–ø—Ä–æ—Å
        analysis = pytorch_expert.analyze_pytorch_question(question)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = pytorch_expert.generate_pytorch_response(question, analysis)
        
        logger.info("‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –æ—Ç–≤–µ—Ç –æ PyTorch")
        
        return jsonify({
            'success': True,
            'response': response,
            'category': analysis['category'],
            'confidence': analysis['confidence'],
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ pytorch_chat: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pytorch/knowledge', methods=['GET'])
def get_pytorch_knowledge():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π PyTorch"""
    try:
        return jsonify({
            'success': True,
            'knowledge_base': pytorch_expert.knowledge_base,
            'learning_paths': pytorch_expert.learning_paths,
            'timestamp': datetime.now().isoformat()
        })
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ get_pytorch_knowledge: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/pytorch/analyze', methods=['POST'])
def analyze_pytorch_code():
    """–ê–Ω–∞–ª–∏–∑ PyTorch –∫–æ–¥–∞"""
    try:
        data = request.get_json()
        code = data.get('code', '')
        
        if not code:
            return jsonify({
                'success': False,
                'error': '–ö–æ–¥ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º'
            }), 400
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞
        analysis = {
            'has_device_management': 'torch.device' in code or '.to(' in code,
            'has_gradient_management': 'zero_grad()' in code,
            'has_model_modes': 'model.train()' in code or 'model.eval()' in code,
            'has_saving': 'torch.save' in code or 'load_state_dict' in code,
            'potential_issues': []
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
        if 'torch.save(model,' in code:
            analysis['potential_issues'].append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ state_dict")
        
        if 'loss.backward()' in code and 'zero_grad()' not in code:
            analysis['potential_issues'].append("–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±–Ω—É–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤")
        
        if 'model.eval()' not in code and 'torch.no_grad()' not in code and 'with torch.no_grad' not in code:
            analysis['potential_issues'].append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å eval() –∏–ª–∏ no_grad() –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π")
        
        return jsonify({
            'success': True,
            'analysis': analysis,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ analyze_pytorch_code: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞"""
    return jsonify({
        'status': 'healthy',
        'service': 'PyTorch Expert Server',
        'timestamp': datetime.now().isoformat(),
        'knowledge_categories': len(pytorch_expert.knowledge_base)
    })

if __name__ == '__main__':
    print("üî• PyTorch Expert Server –∑–∞–ø—É—â–µ–Ω")
    print("URL: http://localhost:8092")
    print("–î–æ—Å—Ç—É–ø–Ω—ã–µ —ç–Ω–¥–ø–æ–∏–Ω—Ç—ã:")
    print("  - POST /api/pytorch/chat - –≤–æ–ø—Ä–æ—Å—ã –æ PyTorch")
    print("  - GET  /api/pytorch/knowledge - –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π")
    print("  - POST /api/pytorch/analyze - –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞")
    print("  - GET  /api/health - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è")
    
    app.run(host='0.0.0.0', port=8092, debug=True)





