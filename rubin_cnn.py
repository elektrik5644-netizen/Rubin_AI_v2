#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CNN (Convolutional Neural Network) –¥–ª—è Rubin AI
–†–µ–∞–ª–∏–∑–∞—Ü–∏—è —Å–≤–µ—Ä—Ç–æ—á–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π
"""

import logging
from typing import Dict, List, Any, Tuple, Optional
import numpy as np

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ ML –±–∏–±–ª–∏–æ—Ç–µ–∫ —Å fallback
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    import torchvision.transforms as transforms
    ML_AVAILABLE = True
except ImportError:
    ML_AVAILABLE = False
    # Mock –∫–ª–∞—Å—Å—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–µ–∑ ML –±–∏–±–ª–∏–æ—Ç–µ–∫
    class torch:
        @staticmethod
        def device(name):
            return name
        
        @staticmethod
        def cuda_is_available():
            return False
        
        @staticmethod
        def FloatTensor(data):
            return data
        
        @staticmethod
        def randn(*args):
            return np.random.randn(*args)
    
    class nn:
        class Module:
            def __init__(self):
                pass
        
        class Conv2d(nn.Module):
            def __init__(self, in_channels, out_channels, kernel_size, **kwargs):
                super().__init__()
                self.in_channels = in_channels
                self.out_channels = out_channels
                self.kernel_size = kernel_size
        
        class Conv1d(nn.Module):
            def __init__(self, in_channels, out_channels, kernel_size, **kwargs):
                super().__init__()
                self.in_channels = in_channels
                self.out_channels = out_channels
                self.kernel_size = kernel_size
        
        class MaxPool2d(nn.Module):
            def __init__(self, kernel_size, **kwargs):
                super().__init__()
                self.kernel_size = kernel_size
        
        class MaxPool1d(nn.Module):
            def __init__(self, kernel_size, **kwargs):
                super().__init__()
                self.kernel_size = kernel_size
        
        class AdaptiveAvgPool2d(nn.Module):
            def __init__(self, output_size):
                super().__init__()
                self.output_size = output_size
        
        class Linear(nn.Module):
            def __init__(self, in_features, out_features):
                super().__init__()
                self.in_features = in_features
                self.out_features = out_features
        
        class ReLU(nn.Module):
            def __init__(self):
                super().__init__()
        
        class Dropout(nn.Module):
            def __init__(self, p=0.5):
                super().__init__()
                self.p = p
        
        class BatchNorm2d(nn.Module):
            def __init__(self, num_features):
                super().__init__()
                self.num_features = num_features
        
        class BatchNorm1d(nn.Module):
            def __init__(self, num_features):
                super().__init__()
                self.num_features = num_features

logging.basicConfig(level=logging.INFO, format='%(levelname)s:%(name)s:%(message)s')
logger = logging.getLogger(__name__)

class RubinCNN2D(nn.Module):
    """2D CNN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ Rubin AI"""
    
    def __init__(self, input_channels=3, num_classes=10, architecture="standard"):
        super(RubinCNN2D, self).__init__()
        
        self.architecture = architecture
        self.input_channels = input_channels
        self.num_classes = num_classes
        
        if architecture == "standard":
            self._build_standard_architecture()
        elif architecture == "deep":
            self._build_deep_architecture()
        elif architecture == "lightweight":
            self._build_lightweight_architecture()
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {architecture}")
    
    def _build_standard_architecture(self):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ CNN"""
        self.features = nn.Sequential(
            # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
            nn.Conv2d(self.input_channels, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(64, self.num_classes)
        )
    
    def _build_deep_architecture(self):
        """–ì–ª—É–±–æ–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ CNN"""
        self.features = nn.Sequential(
            # –ë–ª–æ–∫ 1
            nn.Conv2d(self.input_channels, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # –ë–ª–æ–∫ 2
            nn.Conv2d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.Conv2d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # –ë–ª–æ–∫ 3
            nn.Conv2d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # –ë–ª–æ–∫ 4
            nn.Conv2d(256, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, kernel_size=3, padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(512, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(128, self.num_classes)
        )
    
    def _build_lightweight_architecture(self):
        """–õ–µ–≥–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ CNN"""
        self.features = nn.Sequential(
            # –ë–ª–æ–∫ 1
            nn.Conv2d(self.input_channels, 16, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # –ë–ª–æ–∫ 2
            nn.Conv2d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
            
            # –ë–ª–æ–∫ 3
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Linear(32, self.num_classes)
        )
    
    def forward(self, x):
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ CNN"""
        x = self.features(x)
        x = self.classifier(x)
        return x
    
    def get_feature_maps(self, x):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–∞—Ä—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        feature_maps = []
        for layer in self.features:
            x = layer(x)
            if isinstance(layer, nn.Conv2d):
                feature_maps.append(x)
        return feature_maps

class RubinCNN1D(nn.Module):
    """1D CNN –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –≤ Rubin AI"""
    
    def __init__(self, input_length=100, num_classes=10, architecture="standard"):
        super(RubinCNN1D, self).__init__()
        
        self.architecture = architecture
        self.input_length = input_length
        self.num_classes = num_classes
        
        if architecture == "standard":
            self._build_standard_architecture()
        elif architecture == "deep":
            self._build_deep_architecture()
        elif architecture == "temporal":
            self._build_temporal_architecture()
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {architecture}")
    
    def _build_standard_architecture(self):
        """–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ 1D CNN"""
        self.features = nn.Sequential(
            # –ü–µ—Ä–≤—ã–π –±–ª–æ–∫
            nn.Conv1d(1, 32, kernel_size=3, padding=1),
            nn.BatchNorm1d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            
            # –í—Ç–æ—Ä–æ–π –±–ª–æ–∫
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            
            # –¢—Ä–µ—Ç–∏–π –±–ª–æ–∫
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(128, 64),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(64, self.num_classes)
        )
    
    def _build_deep_architecture(self):
        """–ì–ª—É–±–æ–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ 1D CNN"""
        self.features = nn.Sequential(
            # –ë–ª–æ–∫ 1
            nn.Conv1d(1, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.Conv1d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm1d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            
            # –ë–ª–æ–∫ 2
            nn.Conv1d(64, 128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.Conv1d(128, 128, kernel_size=3, padding=1),
            nn.BatchNorm1d(128),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            
            # –ë–ª–æ–∫ 3
            nn.Conv1d(128, 256, kernel_size=3, padding=1),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Conv1d(256, 256, kernel_size=3, padding=1),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Dropout(0.5),
            nn.Linear(256, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(128, self.num_classes)
        )
    
    def _build_temporal_architecture(self):
        """–í—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
        self.features = nn.Sequential(
            # –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã
            nn.Conv1d(1, 16, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            
            nn.Conv1d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
            
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool1d(kernel_size=2, stride=2),
        )
        
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool1d(1),
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(64, 32),
            nn.ReLU(inplace=True),
            nn.Linear(32, self.num_classes)
        )
    
    def forward(self, x):
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ 1D CNN"""
        x = self.features(x)
        x = self.classifier(x)
        return x

class RubinCNNManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä CNN –¥–ª—è Rubin AI"""
    
    def __init__(self):
        self.device = torch.device("cuda" if torch.cuda.is_available() and ML_AVAILABLE else "cpu")
        self.models = {}
        self.training_history = {}
        logger.info(f"üß† CNN Manager –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ: {self.device}")
    
    def create_cnn_2d(self, input_channels=3, num_classes=10, architecture="standard", model_name="cnn_2d"):
        """–°–æ–∑–¥–∞–Ω–∏–µ 2D CNN"""
        try:
            model = RubinCNN2D(input_channels, num_classes, architecture)
            model = model.to(self.device)
            self.models[model_name] = model
            
            logger.info(f"‚úÖ 2D CNN —Å–æ–∑–¥–∞–Ω–∞: {model_name}")
            logger.info(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {architecture}")
            logger.info(f"   –í—Ö–æ–¥–Ω—ã–µ –∫–∞–Ω–∞–ª—ã: {input_channels}")
            logger.info(f"   –ö–ª–∞—Å—Å—ã: {num_classes}")
            logger.info(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in model.parameters()):,}")
            
            return model
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è 2D CNN: {e}")
            return None
    
    def create_cnn_1d(self, input_length=100, num_classes=10, architecture="standard", model_name="cnn_1d"):
        """–°–æ–∑–¥–∞–Ω–∏–µ 1D CNN"""
        try:
            model = RubinCNN1D(input_length, num_classes, architecture)
            model = model.to(self.device)
            self.models[model_name] = model
            
            logger.info(f"‚úÖ 1D CNN —Å–æ–∑–¥–∞–Ω–∞: {model_name}")
            logger.info(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {architecture}")
            logger.info(f"   –î–ª–∏–Ω–∞ –≤—Ö–æ–¥–∞: {input_length}")
            logger.info(f"   –ö–ª–∞—Å—Å—ã: {num_classes}")
            logger.info(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in model.parameters()):,}")
            
            return model
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è 1D CNN: {e}")
            return None
    
    def train_model(self, model_name, train_data, epochs=10, learning_rate=0.001):
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if model_name not in self.models:
            logger.error(f"‚ùå –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return False
        
        model = self.models[model_name]
        optimizer = optim.Adam(model.parameters(), lr=learning_rate)
        criterion = nn.CrossEntropyLoss()
        
        model.train()
        training_losses = []
        
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_name}")
        logger.info(f"   –≠–ø–æ—Ö–∏: {epochs}")
        logger.info(f"   –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è: {learning_rate}")
        
        for epoch in range(epochs):
            epoch_loss = 0.0
            num_batches = 0
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –æ–±—É—á–µ–Ω–∏—è —Å –¥–∞–Ω–Ω—ã–º–∏
            # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Å–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            if ML_AVAILABLE and train_data is not None:
                # –†–µ–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ
                for batch_idx, (data, target) in enumerate(train_data):
                    data, target = data.to(self.device), target.to(self.device)
                    
                    optimizer.zero_grad()
                    output = model(data)
                    loss = criterion(output, target)
                    loss.backward()
                    optimizer.step()
                    
                    epoch_loss += loss.item()
                    num_batches += 1
            else:
                # Mock –æ–±—É—á–µ–Ω–∏–µ
                epoch_loss = np.random.uniform(0.5, 2.0)
                num_batches = 10
            
            avg_loss = epoch_loss / max(num_batches, 1)
            training_losses.append(avg_loss)
            
            if epoch % 5 == 0:
                logger.info(f"   –≠–ø–æ—Ö–∞ {epoch+1}/{epochs}, –ü–æ—Ç–µ—Ä—è: {avg_loss:.4f}")
        
        self.training_history[model_name] = training_losses
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_name} –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
        
        return True
    
    def predict(self, model_name, data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏"""
        if model_name not in self.models:
            logger.error(f"‚ùå –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return None
        
        model = self.models[model_name]
        model.eval()
        
        with torch.no_grad():
            if ML_AVAILABLE:
                data = data.to(self.device)
                output = model(data)
                predictions = torch.softmax(output, dim=1)
                return predictions.cpu().numpy()
            else:
                # Mock –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                batch_size = data.shape[0] if hasattr(data, 'shape') else 1
                num_classes = model.num_classes
                return np.random.rand(batch_size, num_classes)
    
    def get_model_info(self, model_name):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        if model_name not in self.models:
            return None
        
        model = self.models[model_name]
        
        info = {
            "name": model_name,
            "type": "2D CNN" if isinstance(model, RubinCNN2D) else "1D CNN",
            "architecture": model.architecture,
            "parameters": sum(p.numel() for p in model.parameters()),
            "device": str(self.device),
            "training_history": self.training_history.get(model_name, [])
        }
        
        if isinstance(model, RubinCNN2D):
            info["input_channels"] = model.input_channels
        elif isinstance(model, RubinCNN1D):
            info["input_length"] = model.input_length
        
        info["num_classes"] = model.num_classes
        
        return info
    
    def get_all_models_info(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤—Å–µ—Ö –º–æ–¥–µ–ª—è—Ö"""
        return {name: self.get_model_info(name) for name in self.models.keys()}
    
    def save_model(self, model_name, filepath):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if model_name not in self.models:
            logger.error(f"‚ùå –ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            return False
        
        try:
            if ML_AVAILABLE:
                torch.save(self.models[model_name].state_dict(), filepath)
            else:
                # Mock —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                with open(filepath, 'w') as f:
                    f.write(f"Mock model: {model_name}")
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def load_model(self, model_name, filepath, input_channels=None, input_length=None, num_classes=10, architecture="standard"):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        try:
            if ML_AVAILABLE:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –º–æ–¥–µ–ª–∏ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
                if input_channels is not None:
                    model = RubinCNN2D(input_channels, num_classes, architecture)
                elif input_length is not None:
                    model = RubinCNN1D(input_length, num_classes, architecture)
                else:
                    raise ValueError("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å input_channels –∏–ª–∏ input_length")
                
                model.load_state_dict(torch.load(filepath))
                model = model.to(self.device)
                self.models[model_name] = model
            else:
                # Mock –∑–∞–≥—Ä—É–∑–∫–∞
                model = RubinCNN2D(3, num_classes, architecture) if input_channels else RubinCNN1D(100, num_classes, architecture)
                self.models[model_name] = model
            
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {model_name} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {filepath}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä CNN Manager
_cnn_manager = None

def get_cnn_manager():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ CNN Manager"""
    global _cnn_manager
    if _cnn_manager is None:
        _cnn_manager = RubinCNNManager()
    return _cnn_manager

if __name__ == "__main__":
    print("üß† –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï CNN –î–õ–Ø RUBIN AI")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä CNN
    cnn_manager = get_cnn_manager()
    
    # –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è 2D CNN
    print("\nüìä –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è 2D CNN:")
    cnn_2d = cnn_manager.create_cnn_2d(
        input_channels=3,
        num_classes=10,
        architecture="standard",
        model_name="image_classifier"
    )
    
    if cnn_2d:
        info = cnn_manager.get_model_info("image_classifier")
        print(f"‚úÖ 2D CNN —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {info['parameters']:,}")
        print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {info['architecture']}")
    
    # –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è 1D CNN
    print("\nüìä –¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è 1D CNN:")
    cnn_1d = cnn_manager.create_cnn_1d(
        input_length=100,
        num_classes=5,
        architecture="temporal",
        model_name="sequence_classifier"
    )
    
    if cnn_1d:
        info = cnn_manager.get_model_info("sequence_classifier")
        print(f"‚úÖ 1D CNN —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        print(f"   –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {info['parameters']:,}")
        print(f"   –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: {info['architecture']}")
    
    # –¢–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è
    print("\nüöÄ –¢–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è:")
    if cnn_2d:
        success = cnn_manager.train_model("image_classifier", None, epochs=5)
        if success:
            print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Å–µ—Ö –º–æ–¥–µ–ª—è—Ö
    print("\nüìã –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Å–µ—Ö –º–æ–¥–µ–ª—è—Ö:")
    all_info = cnn_manager.get_all_models_info()
    for name, info in all_info.items():
        print(f"  {name}: {info['type']} - {info['parameters']:,} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    
    print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CNN –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
