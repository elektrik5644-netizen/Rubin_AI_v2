#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üß† RUBIN AI PYTORCH LEARNING MODULE
===================================
–ú–æ–¥—É–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Rubin AI –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö PyTorch —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
"""

import requests
import json
import logging
from datetime import datetime
from typing import Dict, List, Any

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PyTorchLearningModule:
    """–ú–æ–¥—É–ª—å –æ–±—É—á–µ–Ω–∏—è Rubin AI –Ω–∞ PyTorch –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö"""
    
    def __init__(self):
        self.knowledge_base = {
            "pytorch_concepts": [],
            "neural_networks": [],
            "training_methods": [],
            "best_practices": [],
            "common_errors": []
        }
        self.learning_progress = {
            "concepts_learned": 0,
            "last_update": None,
            "confidence_score": 0.0
        }
    
    def extract_pytorch_knowledge(self) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –∏–∑ PyTorch —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        
        logger.info("üîç –ò–∑–≤–ª–µ–∫–∞—é –∑–Ω–∞–Ω–∏—è –∏–∑ PyTorch —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...")
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ PyTorch –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
        pytorch_concepts = {
            "device_selection": {
                "concept": "–í—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ (CPU vs GPU)",
                "description": "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏–π - CUDA (GPU) –∏–ª–∏ CPU",
                "code_example": """
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)
data = data.to(device)
""",
                "importance": "–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏",
                "best_practice": "–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º GPU"
            },
            
            "model_saving": {
                "concept": "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π",
                "description": "–ü—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–¥–µ–ª–∏",
                "code_example": """
# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
torch.save(model.state_dict(), 'model.pth')

# –ó–∞–≥—Ä—É–∑–∫–∞
model = MNISTClassifier()
model.load_state_dict(torch.load('model.pth'))
model.eval()
""",
                "importance": "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è",
                "best_practice": "–°–æ—Ö—Ä–∞–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ state_dict, –Ω–µ –≤—Å—é –º–æ–¥–µ–ª—å"
            },
            
            "gradient_management": {
                "concept": "–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏",
                "description": "–ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–±–Ω—É–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –≤ —Ü–∏–∫–ª–∞—Ö –æ–±—É—á–µ–Ω–∏—è",
                "code_example": """
for data, target in train_loader:
    optimizer.zero_grad()  # –û–±–Ω—É–ª—è–µ–º –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã
    output = model(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()
""",
                "importance": "–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤",
                "best_practice": "–í—Å–µ–≥–¥–∞ –æ–±–Ω—É–ª—è—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã –ø–µ—Ä–µ–¥ backward()"
            },
            
            "model_modes": {
                "concept": "–†–µ–∂–∏–º—ã –º–æ–¥–µ–ª–∏ (train/eval)",
                "description": "–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É —Ä–µ–∂–∏–º–∞–º–∏ –æ–±—É—á–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏",
                "code_example": """
# –ü—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
model.train()

# –ü—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
model.eval()
with torch.no_grad():
    output = model(data)
""",
                "importance": "–í–ª–∏—è–µ—Ç –Ω–∞ –ø–æ–≤–µ–¥–µ–Ω–∏–µ Dropout –∏ BatchNorm",
                "best_practice": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å eval() –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π, train() –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"
            },
            
            "tensor_shapes": {
                "concept": "–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º —Ç–µ–Ω–∑–æ—Ä–æ–≤",
                "description": "–û—Ç–ª–∞–¥–∫–∞ —Ñ–æ—Ä–º –≤—Ö–æ–¥–Ω—ã—Ö –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö",
                "code_example": """
print(f"–§–æ—Ä–º–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {data.shape}")
print(f"–§–æ—Ä–º–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {output.shape}")
print(f"–§–æ—Ä–º–∞ –º–µ—Ç–æ–∫: {target.shape}")
""",
                "importance": "–ö—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏",
                "best_practice": "–í—Å–µ–≥–¥–∞ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ñ–æ—Ä–º—ã —Ç–µ–Ω–∑–æ—Ä–æ–≤ –ø—Ä–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ"
            }
        }
        
        # –û–±—â–∏–µ –æ—à–∏–±–∫–∏ –∏ –∏—Ö —Ä–µ—à–µ–Ω–∏—è
        common_errors = {
            "gradient_accumulation": {
                "error": "–ó–∞–±—ã–ª–∏ –æ–±–Ω—É–ª–∏—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã",
                "symptom": "–ì—Ä–∞–¥–∏–µ–Ω—Ç—ã –Ω–∞–∫–∞–ø–ª–∏–≤–∞—é—Ç—Å—è –º–µ–∂–¥—É –∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏",
                "solution": "–î–æ–±–∞–≤–∏—Ç—å optimizer.zero_grad() –ø–µ—Ä–µ–¥ backward()",
                "prevention": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —à–∞–±–ª–æ–Ω —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è"
            },
            
            "wrong_model_mode": {
                "error": "–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏",
                "symptom": "–ù–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ Dropout/BatchNorm",
                "solution": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å model.train() –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, model.eval() –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è",
                "prevention": "–Ø–≤–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å —Ä–µ–∂–∏–º –º–æ–¥–µ–ª–∏"
            },
            
            "device_mismatch": {
                "error": "–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤",
                "symptom": "RuntimeError: Expected all tensors to be on the same device",
                "solution": "–£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ –Ω–∞ –æ–¥–Ω–æ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–µ",
                "prevention": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å .to(device) –¥–ª—è –≤—Å–µ—Ö —Ç–µ–Ω–∑–æ—Ä–æ–≤"
            },
            
            "state_dict_mismatch": {
                "error": "–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏",
                "symptom": "Missing key(s) in state_dict",
                "solution": "–£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π",
                "prevention": "–°–æ—Ö—Ä–∞–Ω—è—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –≤–º–µ—Å—Ç–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"
            }
        }
        
        # –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏
        best_practices = {
            "data_handling": {
                "practice": "–†–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏",
                "description": "80% —Ä–∞–±–æ—Ç—ã —Å –¥–∞–Ω–Ω—ã–º–∏, 20% –º–∞–≥–∏–∏ –º–æ–¥–µ–ª–µ–π",
                "implementation": "–ù–∞—á–∞—Ç—å —Å –ø—Ä–æ—Å—Ç—ã—Ö –ø—Ä–∏–º–µ—Ä–æ–≤, –ø–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É—Å–ª–æ–∂–Ω—è—Ç—å",
                "benefit": "–ë–æ–ª–µ–µ —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"
            },
            
            "model_architecture": {
                "practice": "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –º–æ–¥–µ–ª–∏",
                "description": "–ù–∞—á–∏–Ω–∞—Ç—å —Å –ø—Ä–æ—Å—Ç—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä",
                "implementation": "–ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ –¥–æ–±–∞–≤–ª—è—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å",
                "benefit": "–õ—É—á—à–µ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"
            },
            
            "training_monitoring": {
                "practice": "–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –æ–±—É—á–µ–Ω–∏—è",
                "description": "–û—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è",
                "implementation": "–õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å loss, accuracy, learning rate",
                "benefit": "–†–∞–Ω–Ω–µ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º"
            },
            
            "reproducibility": {
                "practice": "–í–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å",
                "description": "–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å random seeds",
                "implementation": "torch.manual_seed(42), np.random.seed(42)",
                "benefit": "–°—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–µ–∂–¥—É –∑–∞–ø—É—Å–∫–∞–º–∏"
            }
        }
        
        # –û–±–ª–∞—Å—Ç–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏–∑—É—á–µ–Ω–∏—è
        learning_paths = {
            "cnn": {
                "topic": "–°–≤–µ—Ä—Ç–æ—á–Ω—ã–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (CNN)",
                "description": "–î–ª—è —Ä–∞–±–æ—Ç—ã —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏",
                "difficulty": "–°—Ä–µ–¥–Ω–∏–π",
                "prerequisites": ["–û—Å–Ω–æ–≤—ã PyTorch", "–õ–∏–Ω–µ–π–Ω–∞—è –∞–ª–≥–µ–±—Ä–∞"]
            },
            
            "rnn": {
                "topic": "–†–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã–µ —Å–µ—Ç–∏ (RNN, LSTM)",
                "description": "–î–ª—è —Ä–∞–±–æ—Ç—ã —Å –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è–º–∏",
                "difficulty": "–°—Ä–µ–¥–Ω–∏–π",
                "prerequisites": ["–û—Å–Ω–æ–≤—ã PyTorch", "–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞"]
            },
            
            "transformers": {
                "topic": "–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã",
                "description": "–°–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¥–ª—è NLP –∏ –Ω–µ —Ç–æ–ª—å–∫–æ",
                "difficulty": "–í—ã—Å–æ–∫–∏–π",
                "prerequisites": ["CNN", "RNN", "Attention –º–µ—Ö–∞–Ω–∏–∑–º—ã"]
            },
            
            "transfer_learning": {
                "topic": "–¢—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
                "description": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π",
                "difficulty": "–°—Ä–µ–¥–Ω–∏–π",
                "prerequisites": ["CNN", "Fine-tuning"]
            }
        }
        
        return {
            "concepts": pytorch_concepts,
            "errors": common_errors,
            "practices": best_practices,
            "learning_paths": learning_paths,
            "extraction_time": datetime.now().isoformat(),
            "source": "https://github.com/Shawtysixgoods/PyTorch"
        }
    
    def teach_rubin_pytorch(self) -> Dict[str, Any]:
        """–û–±—É—á–µ–Ω–∏–µ Rubin AI –Ω–∞ PyTorch –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö"""
        
        logger.info("üß† –ù–∞—á–∏–Ω–∞—é –æ–±—É—á–µ–Ω–∏–µ Rubin AI –Ω–∞ PyTorch –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö...")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞–Ω–∏—è
        knowledge = self.extract_pytorch_knowledge()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        self.knowledge_base["pytorch_concepts"] = list(knowledge["concepts"].keys())
        self.knowledge_base["neural_networks"] = ["CNN", "RNN", "LSTM", "Transformers"]
        self.knowledge_base["training_methods"] = ["Gradient Descent", "Backpropagation", "Optimization"]
        self.knowledge_base["best_practices"] = list(knowledge["practices"].keys())
        self.knowledge_base["common_errors"] = list(knowledge["errors"].keys())
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è
        self.learning_progress["concepts_learned"] = len(knowledge["concepts"])
        self.learning_progress["last_update"] = datetime.now().isoformat()
        self.learning_progress["confidence_score"] = 0.85  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ PyTorch –∑–Ω–∞–Ω–∏—è—Ö
        
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ò–∑—É—á–µ–Ω–æ {len(knowledge['concepts'])} –∫–æ–Ω—Ü–µ–ø—Ü–∏–π")
        
        return {
            "status": "success",
            "knowledge_extracted": knowledge,
            "learning_progress": self.learning_progress,
            "knowledge_base": self.knowledge_base
        }
    
    def integrate_with_rubin_ai(self) -> Dict[str, Any]:
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è PyTorch –∑–Ω–∞–Ω–∏–π —Å Rubin AI"""
        
        logger.info("üîó –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É—é PyTorch –∑–Ω–∞–Ω–∏—è —Å Rubin AI...")
        
        try:
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–Ω–∞–Ω–∏—è –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö Rubin AI
            knowledge_data = self.teach_rubin_pytorch()
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
            integration_data = {
                "category": "pytorch_learning",
                "knowledge": knowledge_data["knowledge_extracted"],
                "timestamp": datetime.now().isoformat(),
                "source": "PyTorch Repository",
                "confidence": 0.85
            }
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ Enhanced API (–ø–æ—Ä—Ç 8081)
            response = requests.post(
                "http://localhost:8081/api/knowledge/add",
                json=integration_data,
                timeout=10
            )
            
            if response.status_code == 200:
                logger.info("‚úÖ PyTorch –∑–Ω–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã —Å Rubin AI")
                return {
                    "status": "success",
                    "message": "PyTorch –∑–Ω–∞–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω—ã",
                    "api_response": response.json()
                }
            else:
                logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º–∞ —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π: {response.status_code}")
                return {
                    "status": "partial",
                    "message": "–ó–Ω–∞–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω—ã, –Ω–æ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –Ω–µ–ø–æ–ª–Ω–∞—è",
                    "error": response.text
                }
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {e}")
            return {
                "status": "error",
                "message": "–û—à–∏–±–∫–∞ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å Rubin AI",
                "error": str(e)
            }
    
    def test_rubin_pytorch_knowledge(self) -> Dict[str, Any]:
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π Rubin AI –æ PyTorch"""
        
        logger.info("üß™ –¢–µ—Å—Ç–∏—Ä—É—é –∑–Ω–∞–Ω–∏—è Rubin AI –æ PyTorch...")
        
        test_questions = [
            "–ö–∞–∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤—ã–±—Ä–∞—Ç—å —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è PyTorch?",
            "–ö–∞–∫–∏–µ –æ—à–∏–±–∫–∏ —á–∞—Å—Ç–æ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–∞–º–∏?",
            "–ö–∞–∫ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏ –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å PyTorch?",
            "–í —á–µ–º —Ä–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É train() –∏ eval() —Ä–µ–∂–∏–º–∞–º–∏?",
            "–ö–∞–∫–∏–µ –ª—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏ –¥–ª—è PyTorch —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏?"
        ]
        
        results = []
        
        for question in test_questions:
            try:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Smart Dispatcher
                response = requests.post(
                    "http://localhost:8080/api/chat",
                    json={"message": question},
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    results.append({
                        "question": question,
                        "status": "success",
                        "response": data.get("response", "–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞"),
                        "module": data.get("module", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ")
                    })
                else:
                    results.append({
                        "question": question,
                        "status": "error",
                        "error": f"HTTP {response.status_code}"
                    })
                    
            except Exception as e:
                results.append({
                    "question": question,
                    "status": "error",
                    "error": str(e)
                })
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
        successful_tests = len([r for r in results if r["status"] == "success"])
        total_tests = len(results)
        success_rate = successful_tests / total_tests if total_tests > 0 else 0
        
        logger.info(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {successful_tests}/{total_tests} ({success_rate:.1%})")
        
        return {
            "test_results": results,
            "success_rate": success_rate,
            "successful_tests": successful_tests,
            "total_tests": total_tests
        }

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è Rubin AI –Ω–∞ PyTorch –º–∞—Ç–µ—Ä–∏–∞–ª–∞—Ö"""
    
    print("üß† RUBIN AI PYTORCH LEARNING MODULE")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –º–æ–¥—É–ª—å –æ–±—É—á–µ–Ω–∏—è
    pytorch_learner = PyTorchLearningModule()
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ –æ–±—É—á–∞–µ–º
    print("\n1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–Ω–∞–Ω–∏–π –∏–∑ PyTorch —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...")
    knowledge_result = pytorch_learner.teach_rubin_pytorch()
    
    print(f"‚úÖ –ò–∑—É—á–µ–Ω–æ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π: {knowledge_result['learning_progress']['concepts_learned']}")
    print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {knowledge_result['learning_progress']['confidence_score']:.1%}")
    
    # –ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ–º —Å Rubin AI
    print("\n2. –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å Rubin AI...")
    integration_result = pytorch_learner.integrate_with_rubin_ai()
    
    print(f"üì° –°—Ç–∞—Ç—É—Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏: {integration_result['status']}")
    print(f"üí¨ –°–æ–æ–±—â–µ–Ω–∏–µ: {integration_result['message']}")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–Ω–∞–Ω–∏—è
    print("\n3. –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–Ω–∞–Ω–∏–π Rubin AI...")
    test_result = pytorch_learner.test_rubin_pytorch_knowledge()
    
    print(f"üéØ –£—Å–ø–µ—à–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤: {test_result['success_rate']:.1%}")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {test_result['successful_tests']}/{test_result['total_tests']}")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print("\n" + "=" * 50)
    print("üìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 50)
    print(f"üìö –ò—Å—Ç–æ—á–Ω–∏–∫: PyTorch Repository")
    print(f"üß† –ö–æ–Ω—Ü–µ–ø—Ü–∏–π –∏–∑—É—á–µ–Ω–æ: {knowledge_result['learning_progress']['concepts_learned']}")
    print(f"üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è: {integration_result['status']}")
    print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {test_result['success_rate']:.1%}")
    print(f"‚è∞ –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {knowledge_result['learning_progress']['last_update']}")
    
    if test_result['success_rate'] >= 0.8:
        print("üéâ –û–ë–£–ß–ï–ù–ò–ï –£–°–ü–ï–®–ù–û! Rubin AI –≥–æ—Ç–æ–≤ —Ä–∞–±–æ—Ç–∞—Ç—å —Å PyTorch!")
    elif test_result['success_rate'] >= 0.5:
        print("‚úÖ –û–ë–£–ß–ï–ù–ò–ï –ß–ê–°–¢–ò–ß–ù–û –£–°–ü–ï–®–ù–û. –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞.")
    else:
        print("‚ö†Ô∏è –û–ë–£–ß–ï–ù–ò–ï –¢–†–ï–ë–£–ï–¢ –£–õ–£–ß–®–ï–ù–ò–Ø. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é.")

if __name__ == "__main__":
    main()










