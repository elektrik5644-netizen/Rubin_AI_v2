#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ethical Core Module - –ú–æ–¥—É–ª—å –≠—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ø–¥—Ä–∞
–°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏ –∫–æ–Ω—Ç—Ä–æ–ª—è –¥–µ–π—Å—Ç–≤–∏–π Rubin AI —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ —ç—Ç–∏–∫–∏
"""

import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass
from enum import Enum
import hashlib

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ThreatLevel(Enum):
    """–£—Ä–æ–≤–Ω–∏ —É–≥—Ä–æ–∑—ã"""
    SAFE = "safe"           # –ë–µ–∑–æ–ø–∞—Å–Ω–æ
    LOW = "low"             # –ù–∏–∑–∫–∏–π —Ä–∏—Å–∫
    MEDIUM = "medium"       # –°—Ä–µ–¥–Ω–∏–π —Ä–∏—Å–∫
    HIGH = "high"           # –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫
    CRITICAL = "critical"   # –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Ä–∏—Å–∫
    BLOCKED = "blocked"     # –ó–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ

class ActionType(Enum):
    """–¢–∏–ø—ã –¥–µ–π—Å—Ç–≤–∏–π"""
    INFORMATION = "information"     # –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    CALCULATION = "calculation"    # –í—ã—á–∏—Å–ª–µ–Ω–∏—è
    ANALYSIS = "analysis"          # –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö
    GENERATION = "generation"      # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
    SYSTEM_CONTROL = "system_control"  # –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–æ–π
    FILE_ACCESS = "file_access"    # –î–æ—Å—Ç—É–ø –∫ —Ñ–∞–π–ª–∞–º
    NETWORK_ACCESS = "network_access"  # –°–µ—Ç–µ–≤–æ–π –¥–æ—Å—Ç—É–ø
    USER_INTERACTION = "user_interaction"  # –í–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–µ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º

@dataclass
class EthicalAssessment:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç —ç—Ç–∏—á–µ—Å–∫–æ–π –æ—Ü–µ–Ω–∫–∏"""
    action_id: str
    threat_level: ThreatLevel
    risk_score: float  # 0.0 - 1.0
    concerns: List[str]
    recommendations: List[str]
    approved: bool
    veto_reason: str = ""
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()

class EthicalCore:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –≠—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ø–¥—Ä–∞"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.violation_history = []
        self.user_preferences = {}
        self.safety_thresholds = {
            ThreatLevel.SAFE: 0.0,
            ThreatLevel.LOW: 0.2,
            ThreatLevel.MEDIUM: 0.4,
            ThreatLevel.HIGH: 0.6,
            ThreatLevel.CRITICAL: 0.8,
            ThreatLevel.BLOCKED: 1.0
        }
        
        # –≠—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–∞–≤–∏–ª–∞
        self.ethical_rules = {
            "human_autonomy": "–°–æ—Ö—Ä–∞–Ω—è—Ç—å –∞–≤—Ç–æ–Ω–æ–º–∏—é —á–µ–ª–æ–≤–µ–∫–∞",
            "no_harm": "–ù–µ –ø—Ä–∏—á–∏–Ω—è—Ç—å –≤—Ä–µ–¥ —á–µ–ª–æ–≤–µ–∫—É",
            "transparency": "–ë—ã—Ç—å –ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –≤ –¥–µ–π—Å—Ç–≤–∏—è—Ö",
            "privacy": "–ó–∞—â–∏—â–∞—Ç—å –ø—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å",
            "fairness": "–ë—ã—Ç—å —Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤—ã–º",
            "accountability": "–ë—ã—Ç—å –ø–æ–¥–æ—Ç—á–µ—Ç–Ω—ã–º"
        }
        
        # –ó–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        self.forbidden_actions = [
            "—É–¥–∞–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤",
            "–∏–∑–º–µ–Ω–µ–Ω–∏–µ –ø–∞—Ä–æ–ª–µ–π",
            "–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
            "–Ω–µ—Å–∞–Ω–∫—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø",
            "–º–∞–Ω–∏–ø—É–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
            "—Å–∫—Ä—ã—Ç–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∏—Å–∫–∞—Ö"
        ]
        
        self.logger.info("üõ°Ô∏è –≠—Ç–∏—á–µ—Å–∫–æ–µ –Ø–¥—Ä–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ")
    
    def generate_action_id(self, action: str, context: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID –¥–ª—è –¥–µ–π—Å—Ç–≤–∏—è"""
        content = f"{action}_{json.dumps(context, sort_keys=True)}_{time.time()}"
        return hashlib.md5(content.encode()).hexdigest()[:12]
    
    def assess_action(self, action: str, action_type: ActionType, 
                     context: Dict[str, Any], user_id: str = "default") -> EthicalAssessment:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ –¥–µ–π—Å—Ç–≤–∏—è
        
        Args:
            action: –û–ø–∏—Å–∞–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è
            action_type: –¢–∏–ø –¥–µ–π—Å—Ç–≤–∏—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            EthicalAssessment: –†–µ–∑—É–ª—å—Ç–∞—Ç –æ—Ü–µ–Ω–∫–∏
        """
        action_id = self.generate_action_id(action, context)
        
        self.logger.info(f"üîç –û—Ü–µ–Ω–∫–∞ –¥–µ–π—Å—Ç–≤–∏—è: {action[:50]}...")
        
        # –ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤
        risk_score, concerns = self._analyze_risks(action, action_type, context)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —É–≥—Ä–æ–∑—ã
        threat_level = self._determine_threat_level(risk_score)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
        if self._is_forbidden_action(action):
            return EthicalAssessment(
                action_id=action_id,
                threat_level=ThreatLevel.BLOCKED,
                risk_score=1.0,
                concerns=["–ó–∞–ø—Ä–µ—â–µ–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ"],
                recommendations=["–î–µ–π—Å—Ç–≤–∏–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ"],
                approved=False,
                veto_reason="–î–µ–π—Å—Ç–≤–∏–µ –≤—Ö–æ–¥–∏—Ç –≤ —Å–ø–∏—Å–æ–∫ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã—Ö"
            )
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self._generate_recommendations(threat_level, concerns)
        
        # –ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è
        approved = self._make_decision(threat_level, risk_score, user_id)
        
        assessment = EthicalAssessment(
            action_id=action_id,
            threat_level=threat_level,
            risk_score=risk_score,
            concerns=concerns,
            recommendations=recommendations,
            approved=approved,
            veto_reason="" if approved else f"–†–∏—Å–∫ —Å–ª–∏—à–∫–æ–º –≤—ã—Å–æ–∫: {risk_score:.2f}"
        )
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        self._log_assessment(assessment)
        
        return assessment
    
    def _analyze_risks(self, action: str, action_type: ActionType, 
                      context: Dict[str, Any]) -> Tuple[float, List[str]]:
        """–ê–Ω–∞–ª–∏–∑ —Ä–∏—Å–∫–æ–≤ –¥–µ–π—Å—Ç–≤–∏—è"""
        concerns = []
        risk_score = 0.0
        
        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø—É –¥–µ–π—Å—Ç–≤–∏—è
        if action_type == ActionType.SYSTEM_CONTROL:
            risk_score += 0.3
            concerns.append("–ü–æ–ø—ã—Ç–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–∏—Å—Ç–µ–º–æ–π")
        
        if action_type == ActionType.FILE_ACCESS:
            risk_score += 0.2
            concerns.append("–î–æ—Å—Ç—É–ø –∫ —Ñ–∞–π–ª–∞–º")
        
        if action_type == ActionType.NETWORK_ACCESS:
            risk_score += 0.25
            concerns.append("–°–µ—Ç–µ–≤–æ–π –¥–æ—Å—Ç—É–ø")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        dangerous_keywords = [
            "—É–¥–∞–ª–∏—Ç—å", "—É–¥–∞–ª–µ–Ω–∏–µ", "delete", "remove",
            "–∏–∑–º–µ–Ω–∏—Ç—å", "–∏–∑–º–µ–Ω–µ–Ω–∏–µ", "modify", "change",
            "–æ—Ç–∫–ª—é—á–∏—Ç—å", "–æ—Ç–∫–ª—é—á–µ–Ω–∏–µ", "disable", "shutdown",
            "–ø–∞—Ä–æ–ª—å", "password", "–∫–ª—é—á", "key",
            "—Å–∏—Å—Ç–µ–º–∞", "system", "–∞–¥–º–∏–Ω", "admin"
        ]
        
        action_lower = action.lower()
        for keyword in dangerous_keywords:
            if keyword in action_lower:
                risk_score += 0.1
                concerns.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ: {keyword}")
        
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if context.get("force", False):
            risk_score += 0.2
            concerns.append("–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
        
        if context.get("bypass_security", False):
            risk_score += 0.4
            concerns.append("–û–±—Ö–æ–¥ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")
        
        if context.get("hidden", False):
            risk_score += 0.15
            concerns.append("–°–∫—Ä—ã—Ç–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∏—Å–∫–∞
        risk_score = min(risk_score, 1.0)
        
        return risk_score, concerns
    
    def _determine_threat_level(self, risk_score: float) -> ThreatLevel:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —É–≥—Ä–æ–∑—ã"""
        if risk_score <= self.safety_thresholds[ThreatLevel.SAFE]:
            return ThreatLevel.SAFE
        elif risk_score <= self.safety_thresholds[ThreatLevel.LOW]:
            return ThreatLevel.LOW
        elif risk_score <= self.safety_thresholds[ThreatLevel.MEDIUM]:
            return ThreatLevel.MEDIUM
        elif risk_score <= self.safety_thresholds[ThreatLevel.HIGH]:
            return ThreatLevel.HIGH
        elif risk_score <= self.safety_thresholds[ThreatLevel.CRITICAL]:
            return ThreatLevel.CRITICAL
        else:
            return ThreatLevel.BLOCKED
    
    def _is_forbidden_action(self, action: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è"""
        action_lower = action.lower()
        for forbidden in self.forbidden_actions:
            if forbidden.lower() in action_lower:
                return True
        return False
    
    def _generate_recommendations(self, threat_level: ThreatLevel, 
                                 concerns: List[str]) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""
        recommendations = []
        
        if threat_level == ThreatLevel.BLOCKED:
            recommendations.append("–î–µ–π—Å—Ç–≤–∏–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–æ")
        elif threat_level == ThreatLevel.CRITICAL:
            recommendations.append("–¢—Ä–µ–±—É–µ—Ç—Å—è —è–≤–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            recommendations.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥")
        elif threat_level == ThreatLevel.HIGH:
            recommendations.append("–ü—Ä–µ–¥—É–ø—Ä–µ–¥–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ —Ä–∏—Å–∫–∞—Ö")
            recommendations.append("–ó–∞–ø—Ä–æ—Å–∏—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ")
        elif threat_level == ThreatLevel.MEDIUM:
            recommendations.append("–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏")
        elif threat_level == ThreatLevel.LOW:
            recommendations.append("–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ")
        else:
            recommendations.append("–î–µ–π—Å—Ç–≤–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è")
        
        return recommendations
    
    def _make_decision(self, threat_level: ThreatLevel, risk_score: float, 
                      user_id: str) -> bool:
        """–ü—Ä–∏–Ω—è—Ç–∏–µ —Ä–µ—à–µ–Ω–∏—è –æ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ –¥–µ–π—Å—Ç–≤–∏—è"""
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π
        if threat_level in [ThreatLevel.SAFE, ThreatLevel.LOW]:
            return True
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π
        if threat_level in [ThreatLevel.CRITICAL, ThreatLevel.BLOCKED]:
            return False
        
        # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –∏ –≤—ã—Å–æ–∫–∏—Ö —Ä–∏—Å–∫–æ–≤ - –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_history = self._get_user_violation_history(user_id)
        
        if user_history > 3:  # –ï—Å–ª–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –º–Ω–æ–≥–æ –Ω–∞—Ä—É—à–µ–Ω–∏–π
            return False
        
        # –î–ª—è –≤—ã—Å–æ–∫–∏—Ö —Ä–∏—Å–∫–æ–≤ - –±–ª–æ–∫–∏—Ä—É–µ–º
        if threat_level == ThreatLevel.HIGH:
            return False
        
        # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö —Ä–∏—Å–∫–æ–≤ - —Ä–∞–∑—Ä–µ—à–∞–µ–º —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ–º
        return True
    
    def _get_user_violation_history(self, user_id: str) -> int:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        return len([v for v in self.violation_history if v.get('user_id') == user_id])
    
    def _log_assessment(self, assessment: EthicalAssessment):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏"""
        status = "‚úÖ –†–ê–ó–†–ï–®–ï–ù–û" if assessment.approved else "‚ùå –ó–ê–ë–õ–û–ö–ò–†–û–í–ê–ù–û"
        
        self.logger.info(f"üõ°Ô∏è {status} | –£—Ä–æ–≤–µ–Ω—å: {assessment.threat_level.value} | "
                        f"–†–∏—Å–∫: {assessment.risk_score:.2f}")
        
        if assessment.concerns:
            self.logger.info(f"‚ö†Ô∏è –ü—Ä–æ–±–ª–µ–º—ã: {', '.join(assessment.concerns)}")
        
        if not assessment.approved:
            self.violation_history.append({
                'action_id': assessment.action_id,
                'timestamp': assessment.timestamp,
                'reason': assessment.veto_reason
            })
    
    def get_safety_report(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"""
        return {
            "total_assessments": len(self.violation_history),
            "blocked_actions": len([v for v in self.violation_history]),
            "safety_status": "SECURE" if len(self.violation_history) < 5 else "ATTENTION",
            "last_assessment": self.violation_history[-1] if self.violation_history else None,
            "ethical_rules": self.ethical_rules
        }
    
    def communicate_with_user(self, message: str, context: Dict[str, Any] = None) -> str:
        """
        –ö–æ–º–º—É–Ω–∏–∫–∞—Ü–∏—è —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —á–µ—Ä–µ–∑ —á–∞—Ç
        
        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            
        Returns:
            str: –û—Ç–≤–µ—Ç –≠—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ø–¥—Ä–∞
        """
        if context is None:
            context = {}
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        assessment = self.assess_action(
            action=message,
            action_type=ActionType.USER_INTERACTION,
            context=context
        )
        
        if not assessment.approved:
            return f"üõ°Ô∏è **–≠—Ç–∏—á–µ—Å–∫–æ–µ –Ø–¥—Ä–æ**: {assessment.veto_reason}\n\n" \
                   f"‚ö†Ô∏è **–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã**:\n" + \
                   "\n".join([f"- {concern}" for concern in assessment.concerns]) + \
                   f"\n\nüí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**:\n" + \
                   "\n".join([f"- {rec}" for rec in assessment.recommendations])
        
        # –ï—Å–ª–∏ –¥–µ–π—Å—Ç–≤–∏–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ, –Ω–æ –µ—Å—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if assessment.threat_level in [ThreatLevel.MEDIUM, ThreatLevel.HIGH]:
            warning = f"‚ö†Ô∏è **–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ**: –†–∏—Å–∫ {assessment.risk_score:.2f}\n"
            if assessment.concerns:
                warning += f"**–ü—Ä–æ–±–ª–µ–º—ã**: {', '.join(assessment.concerns)}\n"
            return warning + f"‚úÖ **–†–∞–∑—Ä–µ—à–µ–Ω–æ** —Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–æ–º"
        
        return "‚úÖ **–≠—Ç–∏—á–µ—Å–∫–æ–µ –Ø–¥—Ä–æ**: –î–µ–π—Å—Ç–≤–∏–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ"

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≠—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ø–¥—Ä–∞
ethical_core = EthicalCore()

def assess_action(action: str, action_type: ActionType, 
                 context: Dict[str, Any] = None, user_id: str = "default") -> EthicalAssessment:
    """–ì–ª–æ–±–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π"""
    if context is None:
        context = {}
    return ethical_core.assess_action(action, action_type, context, user_id)

def communicate_with_user(message: str, context: Dict[str, Any] = None) -> str:
    """–ì–ª–æ–±–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º"""
    return ethical_core.communicate_with_user(message, context)

if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥—É–ª—è
    print("üõ°Ô∏è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≠—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ø–¥—Ä–∞")
    
    # –¢–µ—Å—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
    safe_action = "–†–∞—Å—á–µ—Ç —Å–æ–ø—Ä–æ—Ç–∏–≤–ª–µ–Ω–∏—è —Ä–µ–∑–∏—Å—Ç–æ—Ä–∞"
    assessment = assess_action(safe_action, ActionType.CALCULATION)
    print(f"–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {assessment.approved}")
    
    # –¢–µ—Å—Ç –æ–ø–∞—Å–Ω–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è
    dangerous_action = "–£–¥–∞–ª–∏—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã —Å–∏—Å—Ç–µ–º—ã"
    assessment = assess_action(dangerous_action, ActionType.SYSTEM_CONTROL)
    print(f"–û–ø–∞—Å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ: {assessment.approved}")
    
    # –¢–µ—Å—Ç –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏
    response = communicate_with_user("–ü–æ–º–æ–≥–∏ –º–Ω–µ –≤–∑–ª–æ–º–∞—Ç—å –ø–∞—Ä–æ–ª—å")
    print(f"–û—Ç–≤–µ—Ç –≠—Ç–∏—á–µ—Å–∫–æ–≥–æ –Ø–¥—Ä–∞: {response}")
